{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自然语言处理介绍及实践"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 基本概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/nlp.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自然语言处理是计算机科学领域与人工智能领域中的一个重要方向。它研究能实现人与计算机之间用自然语言进行有效通信的各种理论和方法。自然语言处理是一门融语言学、计算机科学、数学于一体的科学。因此，这一领域的研究将涉及自然语言，即人们日常使用的语言，所以它与语言学的研究有着密切的联系，但又有重要的区别。自然语言处理并不是一般地研究自然语言，而在于研制能有效地实现自然语言通信的计算机系统，特别是其中的软件系统。因而它是计算机科学的一部分。\n",
    "\n",
    "自然语言处理（NLP）是计算机科学，人工智能，语言学关注计算机和人类（自然）语言之间的相互作用的领域。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作为data analyst，我们日常中的工作，很大一部分就是将信息从交易所、上市公司、基金公司公布的金融文档中提取出来。\n",
    "\n",
    "比如基金名称，具体的林林总总的金融数据等，如果掌握自然语言处理技巧，或许能够对日常工作如虎添翼。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 主要范畴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文本朗读（Text to speech）/语音合成（Speech synthesis）\n",
    "\n",
    "语音识别（Speech recognition）\n",
    "\n",
    "中文自动分词（Chinese word segmentation）\n",
    "\n",
    "词性标注（Part-of-speech tagging）\n",
    "\n",
    "句法分析（Parsing）\n",
    "\n",
    "自然语言生成（Natural language generation）\n",
    "\n",
    "文本分类（Text categorization）\n",
    "\n",
    "信息检索（Information retrieval）\n",
    "\n",
    "信息抽取（Information extraction）\n",
    "\n",
    "文字校对（Text-proofing）\n",
    "\n",
    "问答系统（Question answering）\n",
    "\n",
    "机器翻译（Machine translation）\n",
    "\n",
    "自动摘要（Automatic summarization）\n",
    "\n",
    "文字蕴涵（Textual entailment）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/nlparc.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 常用套路"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 收集数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于我们analyst来说，就是从我们文档库里面，把我们关心的filing收集起来，然后最好按照句子为单位作为样本进行堆叠。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们拿如下这一段话，进行分句：\n",
    "\n",
    "This prospectus offers variable annuity contract allowing you to accumulate values and paying you benefits on a variable and/or fixed basis. This prospectus provides information regarding the material provisions of your variable annuity contract. We may restrict the availability of this contract to certain broker-dealers. National Security Life V.I. and Annuity Company (\"National Security\") issues the contract. This contract is only available in New York."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitparagraph2sentence(paragraph):\n",
    "    doc = nlp(paragraph)\n",
    "    return [sentence.text for sentence in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This prospectus offers variable annuity contract allowing you to accumulate values and paying you benefits on a variable and/or fixed basis.\n",
      "This prospectus provides information regarding the material provisions of your variable annuity contract.\n",
      "We may restrict the availability of this contract to certain broker-dealers.\n",
      "National Security Life V.I. and Annuity Company (\"National Security\") issues the contract.\n",
      "This contract is only available in New York.\n"
     ]
    }
   ],
   "source": [
    "sentences = splitparagraph2sentence('This prospectus offers variable annuity contract allowing you to accumulate values and paying you benefits on a variable and/or fixed basis. This prospectus provides information regarding the material provisions of your variable annuity contract. We may restrict the availability of this contract to certain broker-dealers. National Security Life V.I. and Annuity Company (\"National Security\") issues the contract. This contract is only available in New York.')\n",
    "for sentence in sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：National Security Life V.I.中的点，没有被无脑作为分句的依据，而是真正根据语义分句。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>如果能够做有监督的分类，就顺手打上标签</b>，因为做无监督的聚类操作，然后根据相似度判断文本类型，耗时耗力，而且效果不是很好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 清洗数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们遵循的第一原则是：“再好的模型也拯救不了shi一样的数据”。所以，先来清洗一下数据吧！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们做以下处理：\n",
    "准则：去除变量，只留常量，或者可常量化。\n",
    "\n",
    "1. 删除所有不相关的字符，如任何非字母数字字符\n",
    "\n",
    "2. 通过文本分隔分成单独的单词来标记你的文章\n",
    "\n",
    "3. 删除不相关的字词，例如“@”推特或网址\n",
    "\n",
    "4. 将所有字符转换为小写字母，以便将诸如“hello”，“Hello”和“HELLO”等单词看做相同单词\n",
    "\n",
    "5. 考虑整合拼写错误或多种拼写的单词，用一个单词代表（例如“cool”/“kewl”/“cooool”）相结合\n",
    "\n",
    "6. 考虑词形还原（把“am”，“are”，“is”等词语缩小为“be”这样的常见形式）\n",
    "\n",
    "7. 将所有专有名词转换为propn这个语义标注词，即变量转换为常量！\n",
    "\n",
    "8. 去除停用词，比如for a an of the and to about after in among as..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "具体实现方式："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 删除所有非字母的字符\n",
    "如这句话：Also assume that, when the Owner is age 76, a step up occurs and the highest quarterly Contract Value is greater than the BDB; in that case, the GAWA percentage will be re determined based on the Owner's attained age of 76, resulting in a new GAWA percentage of 6%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Also assume that when the Owner is age a step up occurs and the highest quarterly Contract Value is greater than the BDB in that case the GAWA percentage will be re determined based on the Owner s attained age of resulting in a new GAWA percentage of\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = '''Also assume that, when the Owner is age 76, a step up occurs and the highest quarterly Contract Value is greater than the BDB; in that case, the GAWA percentage will be re determined based on the Owner's attained age of 76, resulting in a new GAWA percentage of 6%.'''\n",
    "text = re.sub(r'\\W', ' ', text)\n",
    "text = re.sub(r'\\d', ' ', text)\n",
    "text = re.sub(r'( ){2,}', ' ', text).strip()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词性还原"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 什么是词性？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "词性指以词的特点作为划分词类的根据，比如：\n",
    "ADV: 副词；sample：very, well, exactly, tomorrow, up, down\n",
    "\n",
    "VERB: 动词；sample: run, eat, ate, running, eats\n",
    "\n",
    "ADJ: 形容词；sample: big, old, green\n",
    "\n",
    "DET: 限定词；sample: a, an, this, this, no\n",
    "\n",
    "NOUN: 名词；sample: girl, boy, cat, tree\n",
    "\n",
    "ADP: 介词；sample: in, to, during\n",
    "\n",
    "PROPN: 专属名词；sample: Mary, London, HBO, Google\n",
    "\n",
    "CCONJ: 连词；sample: and, or, but\n",
    "\n",
    "参照：http://universaldependencies.org/u/pos/all.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的例子，演示如何通过Spacy获取一句话中各个单词的词性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getwordtokenattributes(text):\n",
    "    doc = nlp(text)\n",
    "    result = []\n",
    "    wordlist = []\n",
    "    for token in doc:\n",
    "#         if token.text not in wordlist:\n",
    "        dictinfo = {}\n",
    "        dictinfo['text'] = token.text\n",
    "        dictinfo['lemma_'] = token.lemma_\n",
    "        dictinfo['pos_'] = token.pos_\n",
    "        dictinfo['tag_'] = token.tag_\n",
    "        dictinfo['dep_'] = token.dep_\n",
    "        dictinfo['shape_'] = token.shape_\n",
    "        dictinfo['is_alpha'] = token.is_alpha\n",
    "        dictinfo['is_stop'] = token.is_stop\n",
    "        wordlist.append(token.text)\n",
    "        result.append(dictinfo)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = getwordtokenattributes(r\"It's supposed to be removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'It', 'lemma_': '-PRON-', 'pos_': 'PRON', 'tag_': 'PRP', 'dep_': 'nsubjpass', 'shape_': 'Xx', 'is_alpha': True, 'is_stop': False}, {'text': \"'s\", 'lemma_': 'be', 'pos_': 'VERB', 'tag_': 'VBZ', 'dep_': 'auxpass', 'shape_': \"'x\", 'is_alpha': False, 'is_stop': False}, {'text': 'supposed', 'lemma_': 'suppose', 'pos_': 'VERB', 'tag_': 'VBN', 'dep_': 'ROOT', 'shape_': 'xxxx', 'is_alpha': True, 'is_stop': False}, {'text': 'to', 'lemma_': 'to', 'pos_': 'PART', 'tag_': 'TO', 'dep_': 'aux', 'shape_': 'xx', 'is_alpha': True, 'is_stop': True}, {'text': 'be', 'lemma_': 'be', 'pos_': 'VERB', 'tag_': 'VB', 'dep_': 'auxpass', 'shape_': 'xx', 'is_alpha': True, 'is_stop': True}, {'text': 'removed', 'lemma_': 'remove', 'pos_': 'VERB', 'tag_': 'VBN', 'dep_': 'xcomp', 'shape_': 'xxxx', 'is_alpha': True, 'is_stop': False}, {'text': '.', 'lemma_': '.', 'pos_': 'PUNCT', 'tag_': '.', 'dep_': 'punct', 'shape_': '.', 'is_alpha': False, 'is_stop': False}]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以用Pandas的DataFrame，将结果变得容易阅读："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dep_</th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>is_stop</th>\n",
       "      <th>lemma_</th>\n",
       "      <th>pos_</th>\n",
       "      <th>shape_</th>\n",
       "      <th>tag_</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nsubjpass</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>PRON</td>\n",
       "      <td>Xx</td>\n",
       "      <td>PRP</td>\n",
       "      <td>It</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>auxpass</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>be</td>\n",
       "      <td>VERB</td>\n",
       "      <td>'x</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>'s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROOT</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>suppose</td>\n",
       "      <td>VERB</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>VBN</td>\n",
       "      <td>supposed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aux</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>to</td>\n",
       "      <td>PART</td>\n",
       "      <td>xx</td>\n",
       "      <td>TO</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>auxpass</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>be</td>\n",
       "      <td>VERB</td>\n",
       "      <td>xx</td>\n",
       "      <td>VB</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xcomp</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>remove</td>\n",
       "      <td>VERB</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>VBN</td>\n",
       "      <td>removed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>punct</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dep_  is_alpha  is_stop   lemma_   pos_ shape_ tag_      text\n",
       "0  nsubjpass      True    False   -PRON-   PRON     Xx  PRP        It\n",
       "1    auxpass     False    False       be   VERB     'x  VBZ        's\n",
       "2       ROOT      True    False  suppose   VERB   xxxx  VBN  supposed\n",
       "3        aux      True     True       to   PART     xx   TO        to\n",
       "4    auxpass      True     True       be   VERB     xx   VB        be\n",
       "5      xcomp      True    False   remove   VERB   xxxx  VBN   removed\n",
       "6      punct     False    False        .  PUNCT      .    .         ."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(result)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 通过词性还原获得语干"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(sentence, allowed_postags=''):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    # allowed_postags, such as 'NOUN,ADJ,VERB,ADV',\n",
    "    # 但是大多数情况，不能加allow_postags，否则很多词，比如no,  or就没有了\n",
    "    if len(allowed_postags) > 0:\n",
    "        resultlist = [token.lemma_\n",
    "                      for token\n",
    "                      in doc\n",
    "                      if token.pos_\n",
    "                      in [postag.upper().strip() for postag in allowed_postags.split(',')]]\n",
    "    else:\n",
    "        resultlist =  [token.lemma_ for token in doc]\n",
    "    return resultlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = r'The product is the best than others.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the product be the good than other .\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(lemmatization(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 通过词性表达式获得短语"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy\n",
    "def extractverbphrase(text, pattern=r'(<ADV>*<NOUN|PROPN>*<VERB><DET>?<ADV>*<VERB|ADJ>+<ADP>?<DET>?<NUM>*<ADJ>*<NOUN|PROPN>*<ADV>?)|(<VERB>?<NOUN|PROPN>*<ADV>?<VERB><ADP>?<ADJ|VERB>*<ADP>?<DET>?<VERB>?<NOUN|PROPN>*)|(<DET>?<ADJ>+<NOUN|PROPN>+)|(<ADV>*<ADJ><ADP><DET>?<VERB|ADJ>*<NOUN|PROPN>*)|(<DET><NOUN><CCONJ><NOUN>)|(<NOUN|PROPN>*<CCONJ>?<NOUN|PROPN>+<ADP><NOUN|PROPN>+)|(<ADP><DET><NOUN|PROPN>+)'):\n",
    "    # ADV: 副词；sample：very, well, exactly, tomorrow, up, down\n",
    "    # VERB: 动词；sample: run, eat, ate, running, eats\n",
    "    # ADJ: 形容词；sample: big, old, green\n",
    "    # DET: 限定词；sample: a, an, this, this, no\n",
    "    # NOUN: 名词；sample: girl, boy, cat, tree\n",
    "    # ADP: 介词；sample: in, to, during\n",
    "    # PROPN: 专属名词；sample: Mary, London, HBO, Google\n",
    "    # CCONJ: 连词；sample: and, or, but\n",
    "    # 参照：http://universaldependencies.org/u/pos/all.html\n",
    "    doc = nlp(text)\n",
    "    return list(textacy.extract.pos_regex_matches(doc, pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "April\n",
      "Investment Divisions\n",
      "Accumulation Unit\n"
     ]
    }
   ],
   "source": [
    "text = r'Effective April 24, 2017, there are new Investment Divisions for which Accumulation Unit information is not yet available.'\n",
    "phraselist = extractverbphrase(text, pattern=r'(<PROPN>+)')\n",
    "for phrase in phraselist:\n",
    "    print(phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 统一的文字清洗方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将清理逻辑连接起来，构成一个统一的文字清洗方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removespecialchar(sentence):\n",
    "    result = re.sub('\\W', ' ', sentence)\n",
    "    return re.sub('( ){2,}', ' ', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearandlemmasentence(sentence,\n",
    "                          stopword='for a an the and in among'):\n",
    "    stoplist = set(stopword.split())\n",
    "    sentence = removespecialchar(sentence).lower().strip()\n",
    "    sentence = ' '.join([word.strip() for word\n",
    "                         in sentence.lower().strip().split()\n",
    "                         if len(word.strip()) > 0\n",
    "                         and word not in stoplist]).strip()\n",
    "    sentence = re.sub(r'(propn\\s+){2,}', 'propn ', sentence)\n",
    "    if len(sentence) == 0:\n",
    "        sentence = 'only for test'\n",
    "    lemmawordlist = lemmatization(sentence)\n",
    "    return lemmawordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacevariabletextfromtextblock(textblock):\n",
    "    \"\"\"\n",
    "    Variable Text:\n",
    "    1. PROPN words, such as: Mainstay VP Funds Trust, replace them with propn\n",
    "    2. Date part, such as January 1, 2018, replace them with date\n",
    "    3. Number, such as 1, 2, replace with space\n",
    "    :param textblock:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # replace date string with \"date\"\n",
    "    datepattern = r'((January|February|March|April|May|June|July|August|September|October|November|December)[\\s]*[0-9]{1,2}[\\s]*,[\\s]*[0-9]{4})|([0-9]{1,2}/[0-9]{1,2}/[0-9]{4})'\n",
    "    textblock = re.sub(datepattern, 'date', textblock)\n",
    "    datepattern = r'\\d{2}\\/\\d{2}\\/(\\d{4}|\\d{2})'\n",
    "    textblock = re.sub(datepattern, 'date', textblock)\n",
    "    # 应对*CTIVP这种情况，无法识别PROPN\n",
    "    textblock = textblock.replace('*', ' ')\n",
    "    textblock = re.sub(r'( ){2,}', ' ', textblock).strip()\n",
    "    # 因为Money Market Fund前缀与后缀词经常是具体的基金公司，\n",
    "    # 所以去除具体基金公司名称的同时，\n",
    "    # 避免其被作为专属名词替换\n",
    "    textblock = textblock.replace(' of ', ' ')\\\n",
    "        .replace(' Inc.', ' ')\\\n",
    "        .replace('&', '')\\\n",
    "        .replace(' LLC ', ' ')\\\n",
    "        .replace(' BlackRock ', ' ')\\\n",
    "        .replace(' SP ', ' ')\n",
    "    textblock = textblock.replace('-', ' ').\\\n",
    "        replace('–', ' ').\\\n",
    "        replace('Addition', 'addition')\n",
    "    textblock = re.sub(r'\\d', ' ', textblock)\n",
    "    textblock = re.sub(r'( ){2,}', ' ', textblock).strip()\n",
    "    phraselist = extractverbphrase(textblock, '<PROPN>+')\n",
    "    phraselist.sort(key=lambda i: len(i), reverse=True)\n",
    "    if len(phraselist) > 0:\n",
    "        for phrase in phraselist:\n",
    "            phrasetext = phrase.text\n",
    "            # avoid remove important words which are related with category\n",
    "            if 'money market fund' in phrasetext.lower():\n",
    "                textblock = textblock.replace(phrasetext, 'money market fund')\n",
    "            noexcludewordlist = ['date',\n",
    "                                 ' merge ',\n",
    "                                 ' merged ',\n",
    "                                 ' merging ',\n",
    "                                 ' merger ',\n",
    "                                 'acquir',\n",
    "                                 'survive',\n",
    "                                 'surviving',\n",
    "                                 'survived',\n",
    "                                 'liquidat',\n",
    "                                 'transfer',\n",
    "                                 'reorganiz',\n",
    "                                 'expense table',\n",
    "                                 'fee summary',\n",
    "                                 'operating expenses',\n",
    "                                 'annual fund',\n",
    "                                 'the adviser',\n",
    "                                 'benefit payment',\n",
    "                                 'variable account option',\n",
    "                                 ' new ']\n",
    "            shouldignore = False\n",
    "            for word in noexcludewordlist:\n",
    "                if word in phrasetext.lower():\n",
    "                    shouldignore = True\n",
    "                    break\n",
    "            if shouldignore:\n",
    "                continue\n",
    "            if not any([phrasetext.lower() == 'fund',\n",
    "                        len(phrasetext.split()) <= 2]):\n",
    "                textblock = textblock.replace(phrasetext, 'propn')\n",
    "    textblock = textblock.replace('PIMCO', ' ')\n",
    "    textblock = re.sub(r'\\W', ' ', textblock)\n",
    "    textblock = re.sub(r'(propn\\s+){2,}', 'propn ', textblock)\n",
    "    textblock = re.sub(r'( ){2,}', ' ', textblock).strip()\n",
    "    return textblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleardatafordoc2vector(doc):\n",
    "    temp = ' '.join(\n",
    "        clearandlemmasentence(replacevariabletextfromtextblock(doc),\n",
    "                              'for a an of the and or to about after in among as at be been was were is are being b c d e f g h i j k l m n o p q r s t u v w x y z'\n",
    "                              )).strip()\n",
    "    temp = temp.replace('-PRON-', 'pron')\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在可以做一下效果测试：<br>\n",
    "原句：122 66 32 15 14 5 13 17 *CTIVP SM – Eaton Vance Floating Rate Income Fund (Class 2) liquidated on April 27, 2018. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "propn class liquidate on date\n"
     ]
    }
   ],
   "source": [
    "text = r'122 66 32 15 14 5 13 17 *CTIVP SM – Eaton Vance Floating Rate Income Fund (Class 2) liquidated on April 27, 2018. '\n",
    "print(cleardatafordoc2vector(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 找到一个好的数据表示方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 词袋化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag-of-words模型是信息检索领域常用的文档表示方法。\n",
    "\n",
    "在信息检索中，BOW模型假定对于一个文档，忽略它的单词顺序和语法、句法等要素，将其仅仅看作是若干个词汇的集合，文档中每个单词的出现都是独立的，不依赖于其它单词是否出现。\n",
    "\n",
    "也就是说，文档中任意一个位置出现的任何单词，都不受该文档语意影响而独立选择的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "词袋模型的缺点："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "词袋模型最重要的是构造词表，然后通过文本为词表中的词赋值，但词袋模型严重缺乏相似词之间的表达。 \n",
    "\n",
    "比如“我喜欢北京”“我不喜欢北京”其实这两个文本是严重不相似的。但词袋模型会判为高度相似。 \n",
    "\n",
    "“我喜欢北京”与“我爱北京”其实表达的意思是非常非常的接近的，但词袋模型不能表示“喜欢”和“爱”之间严重的相似关系。（当然词袋模型也能给这两句话很高的相似度，但是注意我想表达的含义）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在Investment名字相似度这个应用中，正是采用了词袋 + TF/IDF模型 + 余弦相似度作为核心。因为单纯的investment并不存在或者很少存在需要语义分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是代码示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python36\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "namelist = [\n",
    "    'ODDO BHF US Mid Cap CI-EUR H',\n",
    "    'ODDO BHF US Mid Cap CR-USD',\n",
    "    'Credit Suisse Index Fund (CH) - CSIF (CH) Bond Fiscal Strength EUR Blue ZA',\n",
    "    'Winton Diversified Futures Fund (Luxembourg) C GBP Acc',\n",
    "    'Prescient Core Equity Fund B5',\n",
    "    'Robeco QI GTAA Plus DHL $',\n",
    "    'Franklin US Rising Dividends T',\n",
    "    'FT MLP Closed-End Fund & Energy 52 CA',\n",
    "    'FT Richard Bern Adv TS Amer Ind 16-3 CA',\n",
    "    'FT Municipal FT Income Select CE 81 CA',\n",
    "    'Raiffeisen-Pensionsfonds-Österreich 2007 VT',\n",
    "    'Multipartner SICAV - Carthesio Asian Credit Fund B EUR',\n",
    "    'HSBC Wealth Strategic Solutions Fund (1) - Conservative Portfolio Income X',\n",
    "    'American Beacon Flexible Bond Fund A Class',\n",
    "    'Robeco QI GTAA Plus IHL $',\n",
    "    'AXA World Funds - Global Equity Income M Capitalisation EUR']\n",
    "stoplist = set('for a an of the and to in - $ &'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ODDO', 'BHF', 'US', 'Mid', 'Cap', 'CI-EUR', 'H'], ['ODDO', 'BHF', 'US', 'Mid', 'Cap', 'CR-USD'], ['Credit', 'Suisse', 'Index', 'Fund', '(CH)', 'CSIF', '(CH)', 'Bond', 'Fiscal', 'Strength', 'EUR', 'Blue', 'ZA'], ['Winton', 'Diversified', 'Futures', 'Fund', '(Luxembourg)', 'C', 'GBP', 'Acc'], ['Prescient', 'Core', 'Equity', 'Fund', 'B5'], ['Robeco', 'QI', 'GTAA', 'Plus', 'DHL'], ['Franklin', 'US', 'Rising', 'Dividends', 'T'], ['FT', 'MLP', 'Closed-End', 'Fund', 'Energy', '52', 'CA'], ['FT', 'Richard', 'Bern', 'Adv', 'TS', 'Amer', 'Ind', '16-3', 'CA'], ['FT', 'Municipal', 'FT', 'Income', 'Select', 'CE', '81', 'CA'], ['Raiffeisen-Pensionsfonds-Österreich', '2007', 'VT'], ['Multipartner', 'SICAV', 'Carthesio', 'Asian', 'Credit', 'Fund', 'B', 'EUR'], ['HSBC', 'Wealth', 'Strategic', 'Solutions', 'Fund', '(1)', 'Conservative', 'Portfolio', 'Income', 'X'], ['American', 'Beacon', 'Flexible', 'Bond', 'Fund', 'A', 'Class'], ['Robeco', 'QI', 'GTAA', 'Plus', 'IHL'], ['AXA', 'World', 'Funds', 'Global', 'Equity', 'Income', 'M', 'Capitalisation', 'EUR']]\n"
     ]
    }
   ],
   "source": [
    "data_train = []\n",
    "for name in namelist:\n",
    "    data_train.append([word for word in name.strip().split() \n",
    "                       if word not in stoplist])\n",
    "print(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的代码演示如何生成词袋字典以及词袋模型，并保存为具体的文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出每个单词对应的索引编号\n",
      "{'BHF': 0, 'CI-EUR': 1, 'Cap': 2, 'H': 3, 'Mid': 4, 'ODDO': 5, 'US': 6, 'CR-USD': 7, '(CH)': 8, 'Blue': 9, 'Bond': 10, 'CSIF': 11, 'Credit': 12, 'EUR': 13, 'Fiscal': 14, 'Fund': 15, 'Index': 16, 'Strength': 17, 'Suisse': 18, 'ZA': 19, '(Luxembourg)': 20, 'Acc': 21, 'C': 22, 'Diversified': 23, 'Futures': 24, 'GBP': 25, 'Winton': 26, 'B5': 27, 'Core': 28, 'Equity': 29, 'Prescient': 30, 'DHL': 31, 'GTAA': 32, 'Plus': 33, 'QI': 34, 'Robeco': 35, 'Dividends': 36, 'Franklin': 37, 'Rising': 38, 'T': 39, '52': 40, 'CA': 41, 'Closed-End': 42, 'Energy': 43, 'FT': 44, 'MLP': 45, '16-3': 46, 'Adv': 47, 'Amer': 48, 'Bern': 49, 'Ind': 50, 'Richard': 51, 'TS': 52, '81': 53, 'CE': 54, 'Income': 55, 'Municipal': 56, 'Select': 57, '2007': 58, 'Raiffeisen-Pensionsfonds-Österreich': 59, 'VT': 60, 'Asian': 61, 'B': 62, 'Carthesio': 63, 'Multipartner': 64, 'SICAV': 65, '(1)': 66, 'Conservative': 67, 'HSBC': 68, 'Portfolio': 69, 'Solutions': 70, 'Strategic': 71, 'Wealth': 72, 'X': 73, 'A': 74, 'American': 75, 'Beacon': 76, 'Class': 77, 'Flexible': 78, 'IHL': 79, 'AXA': 80, 'Capitalisation': 81, 'Funds': 82, 'Global': 83, 'M': 84, 'World': 85}\n",
      "输出当前句子中各个单词的索引编号以及出现频率\n",
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)]\n",
      "[(0, 1), (2, 1), (4, 1), (5, 1), (6, 1), (7, 1)]\n",
      "[(8, 2), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1)]\n",
      "[(15, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1)]\n",
      "[(15, 1), (27, 1), (28, 1), (29, 1), (30, 1)]\n",
      "[(31, 1), (32, 1), (33, 1), (34, 1), (35, 1)]\n",
      "[(6, 1), (36, 1), (37, 1), (38, 1), (39, 1)]\n",
      "[(15, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1)]\n",
      "[(41, 1), (44, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1)]\n",
      "[(41, 1), (44, 2), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1)]\n",
      "[(58, 1), (59, 1), (60, 1)]\n",
      "[(12, 1), (13, 1), (15, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1)]\n",
      "[(15, 1), (55, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1)]\n",
      "[(10, 1), (15, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1)]\n",
      "[(32, 1), (33, 1), (34, 1), (35, 1), (79, 1)]\n",
      "[(13, 1), (29, 1), (55, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1)]\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(data_train)\n",
    "print('输出每个单词对应的索引编号')\n",
    "print(dictionary.token2id)\n",
    "dictpath = './nlpmodel/corpus.dict'\n",
    "dictionary.save(dictpath)\n",
    "corpus = [dictionary.doc2bow(text) for text in data_train]\n",
    "print('输出当前句子中各个单词的索引编号以及出现频率')\n",
    "for corpu in corpus:\n",
    "    print(corpu)\n",
    "modelpath = './nlpmodel/corpus.mm'\n",
    "corpora.MmCorpus.serialize(modelpath, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下文将演示如何通过TF/IDF模型求语句相似度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "corpus = corpora.MmCorpus(modelpath)\n",
    "dictionary = corpora.Dictionary.load(dictpath)\n",
    "tfidf_model = models.TfidfModel(corpus)\n",
    "index = similarities.SparseMatrixSimilarity(\n",
    "    tfidf_model[corpus],\n",
    "    num_features=len(dictionary.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准备测试语句\n",
      "[(0, 1), (2, 2), (4, 1), (5, 1), (6, 1), (7, 1)]\n"
     ]
    }
   ],
   "source": [
    "print('准备测试语句')\n",
    "testtext = 'CR-USD ODDO Mid Cap Cap BHF US'.split()\n",
    "doc_text_vec = dictionary.doc2bow(testtext)\n",
    "print(doc_text_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "直接通过TF/IDF模型获取相似度, 返回数值越大，相似度越高\n",
      "[2.0267534  2.8160036  0.         0.         0.         0.\n",
      " 0.28899837 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print('直接通过TF/IDF模型获取相似度, 返回数值越大，相似度越高')\n",
    "print(index.get_similarities(doc_text_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0.9541586), (0, 0.6422975)]\n"
     ]
    }
   ],
   "source": [
    "test_simi = index[tfidf_model[doc_text_vec]]\n",
    "test_simi = sorted(enumerate(test_simi), key=lambda item: -item[1])\n",
    "outputlist = [test for test in test_simi if test[1] > 0.2]\n",
    "print(outputlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果想看与哪一句最相似，直接使用索引，从语料包拿就可以"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw sentence:  CR-USD ODDO Mid Cap Cap BHF US\n",
      "ODDO BHF US Mid Cap CR-USD ---------similarity:  0.9541586\n",
      "ODDO BHF US Mid Cap CI-EUR H ---------similarity:  0.6422975\n"
     ]
    }
   ],
   "source": [
    "print('raw sentence: ', ' '.join(testtext))\n",
    "for output in outputlist:\n",
    "    print(namelist[output[0]],'---------similarity: ', output[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Doc2Vector中的TaggedDocument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc2Vector其实与Word2Vector类似，都有语义分析成分，但是索引单位是句子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc2Vector的训练集的组成单元是TaggedDocument对象, 如下是官方说明："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represents a document along with a tag, input document format for class: `gensim.models.doc2vec.Doc2Vec`.\n",
    "\n",
    "A single document, made up of `words` (a list of unicode string tokens) and `tags` (a list of tokens).\n",
    "\n",
    "Tags may be one or more unicode string tokens, but typical practice (which will also be the most memory-efficient) is for the tags list to include a unique integer id as the only tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaggedDocument(['may', 'prize', 'winner', 'teacher', 'bomb'], ['0'])\n",
      "TaggedDocument(['production', 'value', 'use', 'cgi', 'digital', 'ink', 'paint', 'make', 'thing', 'look', 'really', 'slick', 'voice', 'fine', 'well', 'problem', 'thing', 'script'], ['1'])\n",
      "TaggedDocument(['got', 'heart', 'right', 'place', 'also', 'wilt', 'awhile'], ['2'])\n",
      "TaggedDocument(['prof', 'movie', 'goodness', 'thing', 'good', 'movie'], ['3'])\n",
      "TaggedDocument(['well', 'go', 'forever'], ['4'])\n",
      "TaggedDocument(['overproduced', 'generally', 'disappointing', 'effort', 'likely', 'rouse', 'rush', 'hour', 'crowd'], ['5'])\n"
     ]
    }
   ],
   "source": [
    "sentencelist = [\n",
    "    'may prize winner teacher bomb',\n",
    "    'production value use cgi digital ink paint make thing look really slick voice fine well problem thing script',\n",
    "    'got heart right place also wilt awhile',\n",
    "    'prof movie goodness thing good movie',\n",
    "    'well go forever',\n",
    "    'overproduced generally disappointing effort likely rouse rush hour crowd']\n",
    "x_train = []\n",
    "for index, sentence in enumerate(sentencelist):\n",
    "    document = TaggedDocument(sentence.split(), tags=['{0}'.format(index)])\n",
    "    print(document)\n",
    "    x_train.append(document)\n",
    "# model_dm = Doc2Vec(x_train, min_count=1, window=3, size=200, sample=1e-3, negative=5, workers=2)\n",
    "# print(model_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 Keras中的Tokenizer与pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text.Tokenizer类\n",
    "\n",
    "这个类用来对文本中的词进行统计计数，生成文档词典，以支持基于词典位序生成文本的向量表示。 \n",
    "init(num_words) 构造函数，传入词典的最大值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 成员函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fit_on_text(texts) 使用一系列文档来生成token词典，texts为list类，每个元素为一个文档。\n",
    "- texts_to_sequences(texts) 将多个文档转换为word下标的向量形式,shape为`[len(texts)，len(text)]` -- (文档数，每条文档的长度)\n",
    "- texts_to_matrix(texts) 将多个文档转换为矩阵表示,shape为`[len(texts),num_words]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 成员变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- document_count 处理的文档数量\n",
    "- word_index 一个dict，保存所有word对应的编号id，从<b>1</b>开始\n",
    "- word_counts 一个dict，保存每个word在所有文档中出现的次数\n",
    "- word_docs 一个dict，保存每个word出现的文档的数量\n",
    "- index_docs 一个dict，保存word的id出现的文档的数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentencelist = [\n",
    "    'may prize winner teacher bomb',\n",
    "    'production value use cgi digital ink paint make thing look really slick voice fine well problem thing script',\n",
    "    'got heart right place also wilt awhile',\n",
    "    'prof movie goodness thing good movie',\n",
    "    'well go forever',\n",
    "    'overproduced generally disappointing effort likely rouse rush hour crowd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_to_word_sequence的用法与字符串的split用法类似\n",
      "['may', 'prize', 'winner', 'teacher', 'bomb']\n"
     ]
    }
   ],
   "source": [
    "print('text_to_word_sequence的用法与字符串的split用法类似')\n",
    "print(text_to_word_sequence(sentencelist[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fatures = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.word_counts\n",
      "OrderedDict([('may', 1), ('prize', 1), ('winner', 1), ('teacher', 1), ('bomb', 1), ('production', 1), ('value', 1), ('use', 1), ('cgi', 1), ('digital', 1), ('ink', 1), ('paint', 1), ('make', 1), ('thing', 3), ('look', 1), ('really', 1), ('slick', 1), ('voice', 1), ('fine', 1), ('well', 2), ('problem', 1), ('script', 1), ('got', 1), ('heart', 1), ('right', 1), ('place', 1), ('also', 1), ('wilt', 1), ('awhile', 1), ('prof', 1), ('movie', 2), ('goodness', 1), ('good', 1), ('go', 1), ('forever', 1), ('overproduced', 1), ('generally', 1), ('disappointing', 1), ('effort', 1), ('likely', 1), ('rouse', 1), ('rush', 1), ('hour', 1), ('crowd', 1)])\n",
      "\n",
      "tokenizer.word_index\n",
      "{'thing': 1, 'well': 2, 'movie': 3, 'may': 4, 'prize': 5, 'winner': 6, 'teacher': 7, 'bomb': 8, 'production': 9, 'value': 10, 'use': 11, 'cgi': 12, 'digital': 13, 'ink': 14, 'paint': 15, 'make': 16, 'look': 17, 'really': 18, 'slick': 19, 'voice': 20, 'fine': 21, 'problem': 22, 'script': 23, 'got': 24, 'heart': 25, 'right': 26, 'place': 27, 'also': 28, 'wilt': 29, 'awhile': 30, 'prof': 31, 'goodness': 32, 'good': 33, 'go': 34, 'forever': 35, 'overproduced': 36, 'generally': 37, 'disappointing': 38, 'effort': 39, 'likely': 40, 'rouse': 41, 'rush': 42, 'hour': 43, 'crowd': 44}\n",
      "\n",
      "tokenizer.word_docs\n",
      "defaultdict(<class 'int'>, {'winner': 1, 'teacher': 1, 'bomb': 1, 'prize': 1, 'may': 1, 'ink': 1, 'well': 2, 'paint': 1, 'voice': 1, 'make': 1, 'thing': 2, 'value': 1, 'use': 1, 'slick': 1, 'really': 1, 'look': 1, 'digital': 1, 'script': 1, 'cgi': 1, 'problem': 1, 'fine': 1, 'production': 1, 'place': 1, 'wilt': 1, 'heart': 1, 'got': 1, 'right': 1, 'awhile': 1, 'also': 1, 'movie': 1, 'goodness': 1, 'good': 1, 'prof': 1, 'forever': 1, 'go': 1, 'rush': 1, 'likely': 1, 'overproduced': 1, 'rouse': 1, 'crowd': 1, 'disappointing': 1, 'hour': 1, 'generally': 1, 'effort': 1})\n",
      "\n",
      "tokenizer.index_docs\n",
      "defaultdict(<class 'int'>, {6: 1, 7: 1, 8: 1, 5: 1, 4: 1, 14: 1, 2: 2, 15: 1, 20: 1, 16: 1, 1: 2, 10: 1, 11: 1, 19: 1, 18: 1, 17: 1, 13: 1, 23: 1, 12: 1, 22: 1, 21: 1, 9: 1, 27: 1, 29: 1, 25: 1, 24: 1, 26: 1, 30: 1, 28: 1, 3: 1, 32: 1, 33: 1, 31: 1, 35: 1, 34: 1, 42: 1, 40: 1, 36: 1, 41: 1, 44: 1, 38: 1, 43: 1, 37: 1, 39: 1})\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(sentencelist)\n",
    "print('tokenizer.word_counts')\n",
    "print(tokenizer.word_counts)\n",
    "print()\n",
    "print('tokenizer.word_index')\n",
    "print(tokenizer.word_index)\n",
    "print()\n",
    "print('tokenizer.word_docs')\n",
    "print(tokenizer.word_docs)\n",
    "\n",
    "print()\n",
    "print('tokenizer.index_docs')\n",
    "print(tokenizer.index_docs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15, 16, 1, 17, 18, 19, 20, 21, 2, 22, 1, 23], [24, 25, 26, 27, 28, 29, 30], [31, 3, 32, 1, 33, 3], [2, 34, 35], [36, 37, 38, 39, 40, 41, 42, 43, 44]]\n"
     ]
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(sentencelist)\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One_Hot化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.texts_to_matrix(sentencelist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pad_sequences非常重要，目的是将序列填充到maxlen长度，不足maxlenth的句子，用0填充\n",
    "\n",
    "<b><font color='red'>这个非常重要，Keras用于做分类训练的样本，需要通过填充对齐，才能进行之后的训练</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  5  6  7  8]\n",
      " [ 0  0  9 10 11 12 13 14 15 16  1 17 18 19 20 21  2 22  1 23]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 24 25 26 27 28 29 30]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 31  3 32  1 33  3]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2 34 35]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 36 37 38 39 40 41 42 43 44]]\n"
     ]
    }
   ],
   "source": [
    "X = pad_sequences(sequences, maxlen=20)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文本清洗，词袋化或“向量化”（这里向量化打引号，表示与真正的词向量概率不同，这里仅仅是将词或句建立向量索引）之后，就是建模了。\n",
    "\n",
    "上述部分已经提及了如何创建TF/IDF这种简单模型，那么如何创建词向量模型(word2vec)，句向量(doc2vec)以及通过Keras创建LSTM, biLSTM, GRU乃至biGRU模型呢？\n",
    "\n",
    "我们将在`5. 常用模型`这一章详细了解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 使用模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将在`5. 常用模型`这一章详细了解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 常用自然语言处理包"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "工欲善其事，必先利其器。目前为止已经有很多很多用于NLP专项应用的python包。\n",
    "\n",
    "下面将逐一介绍它们。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/gensimoffice.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim是一个用于从文档中自动提取语义主题的Python库，足够智能。\n",
    "\n",
    "Gensim可以处理原生，非结构化的数值化文本(纯文本)。Gensim里面的算法，比如Latent Semantic Analysis(潜在语义分析LSA)，Latent Dirichlet Allocation，Random Projections，通过在语料库的训练下检验词的统计共生模式(statistical co-occurrence patterns)来发现文档的语义结构。\n",
    "\n",
    "这些算法是无监督的，也就是说你只需要一个语料库的文档集。\n",
    "\n",
    "当得到这些统计模式后，任何文本都能够用语义表示(semantic representation)来简洁的表达，并得到一个局部的相似度与其他文本区分开来。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "常用的功能有：语料(Corpus)，TF/IDF、LSA、LDA模型，Word2Vec, Doc2Vec, 以及通过各种模型获得单词、语句间的相似度。这些都是无监督使用方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是，如果Doc2Vec的TaggedDocument使用得当，甚至可以起到有监督的语句分类的功效。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "安装方式：`pip install -U gensim`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以从Github获取源码：[Gensim on Github](https://github.com/RaRe-Technologies/gensim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/gensimongithub.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "官方站点：[Gensim](https://radimrehurek.com/gensim/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/gensimoffice2.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第三方文档教程：[gensim](https://kite.com/python/docs/gensim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/gensimonkite.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很有特色的英文教程：[Gensim Tutorial – A Complete Beginners Guide](https://www.machinelearningplus.com/nlp/gensim-tutorial/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/gensimtutorial.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy是由`Cython`编写，因此它是一个非常快的库，可以说是工业级别的NLP组件库。\n",
    "\n",
    "Spacy源自预训练统计模型，词向量，并且支持30+语言。\n",
    "\n",
    "其号称具有最快的语法解析器，通过卷积神经网络CNN（convolutional neural network models）做token标注、解析以及命名实体识别，并且很方便做深度学习整合应用。\n",
    "\n",
    "Spacy是商业开源软件，基于MIT license发布。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy的特点与功能：\n",
    "\n",
    "- Fastest syntactic parser in the world\n",
    "- Named entity recognition\n",
    "- Non-destructive tokenization\n",
    "- Support for 30+ languages\n",
    "- Pre-trained statistical models and word vectors\n",
    "- Easy deep learning integration\n",
    "- Part-of-speech tagging\n",
    "- Labelled dependency parsing\n",
    "- Syntax-driven sentence segmentation\n",
    "- Built in visualizers for syntax and NER\n",
    "- Convenient string-to-hash mapping\n",
    "- Export to numpy data arrays\n",
    "- Efficient binary serialization\n",
    "- Easy model packaging and deployment\n",
    "- State-of-the-art speed\n",
    "- Robust, rigorously evaluated accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "安装方式：`pip install spacy`或者`pip install -U spacy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在第三章中，我们使用Spacy做了分句，单词原型化，根据词性表达式获取短语等应用，而这一切都是是基于模型应用的，下面介绍如何下载语言模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最简单的下载模型方式，是基于Spacy的download命令："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# out-of-the-box: download best-matching default model\n",
    "python -m spacy download en\n",
    "python -m spacy download de\n",
    "python -m spacy download es\n",
    "python -m spacy download pt\n",
    "python -m spacy download fr\n",
    "python -m spacy download it\n",
    "python -m spacy download nl\n",
    "python -m spacy download xx\n",
    "\n",
    "# download best-matching version of specific model for your spaCy installation\n",
    "python -m spacy download en_core_web_sm\n",
    "\n",
    "# download exact model version (doesn't create shortcut link)\n",
    "python -m spacy download en_core_web_sm-2.0.0 --direct\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型下载相关的文档位于：[Models Overview](https://spacy.io/models/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果想获得特别全的英文词向量模型，可以下载：`python -m spacy download en_core_web_lg`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "昨天举了很多Spacy有关的例子，这里再举一个命名实体识别的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PERSON': ['Mary'], 'ORG': ['Google,', 'Amazon'], 'GPE': ['New York']}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "doc = nlp(\"\"\"Mary has a dog, she works for Google, \n",
    "and likes to buy things on Amazon, \n",
    "she is living in New York.\"\"\")\n",
    "result = {}\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ not in result.keys():\n",
    "        result[ent.label_] = []\n",
    "    if ent.text.strip() != \"\":\n",
    "        result[ent.label_].append(ent.text.strip())\n",
    "#remove duplicate entity values\n",
    "for key in result.keys():\n",
    "    l = []\n",
    "    for label in result[key]:\n",
    "        if not label in l:\n",
    "            l.append(label)\n",
    "    result[key] = l\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "命名实体识别可视化的方式：\n",
    "\n",
    "通过如下代码，即可通过访问http://localhost:5000 的网址浏览实体识别的具体信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Serving on port 5000...\n",
      "    Using the 'ent' visualizer\n",
      "\n",
      "\n",
      "    Shutting down server on port 5000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.serve(doc, style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "效果大致如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/spacyentity.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Github地址：[spaCy: Industrial-strength NLP](https://github.com/explosion/spaCy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/spacygithub.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "官方介绍及教程：[Spacy: Industrial-Strength\n",
    "Natural Language\n",
    "Processing](https://spacy.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 textacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "textacy是基于Spacy开发的自然语言任务工具，相关特性如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Provide a convenient entry point and interface to one or many documents, with the core processing delegated to spaCy\n",
    "- Stream text, json, csv, spaCy binary, and other data to and from disk\n",
    "- Download and explore a variety of included datasets with both text content and metadata, from Congressional speeches to historical literature to Reddit comments\n",
    "- Clean and normalize raw text, before analyzing it\n",
    "- Access and filter basic linguistic elements, such as words, ngrams, and noun chunks; extract named entities, acronyms and their definitions, and key terms\n",
    "- Flexibly tokenize and vectorize documents and corpora, then train, interpret, and visualize topic models using LSA, LDA, or NMF methods\n",
    "- Compare strings, sets, and documents by a variety of similarity metrics\n",
    "- Calculate common text statistics, including Flesch-Kincaid Grade Level, SMOG Index, and multilingual Flesch Reading Ease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "安装方法：`pip install textacy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之所以用textacy，是因为其可以预处理文本，比如:\n",
    "去除URLs: 统一替换为url\n",
    "Email：统一替换为email\n",
    "Number: 统一替换为number\n",
    "标点符号，\n",
    "重音符号，\n",
    "HTML标记等，如： "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please visit url then you will get what you want to search there are over number web pages to review please contact me by email\n"
     ]
    }
   ],
   "source": [
    "import textacy\n",
    "rawtext = \"\"\"Please visit http://www.google.com, \n",
    "then you will get what you want to search. \n",
    "There are over 1000 web pages to review.\n",
    "Please contact me by a@gmail.com.\"\"\"\n",
    "text = textacy.preprocess_text(rawtext, \n",
    "                               no_urls=True, \n",
    "                               no_numbers=True, \n",
    "                               no_emails=True,\n",
    "                               lowercase=True, \n",
    "                               no_punct=True)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function preprocess_text in module textacy.preprocess:\n",
      "\n",
      "preprocess_text(text, fix_unicode=False, lowercase=False, transliterate=False, no_urls=False, no_emails=False, no_phone_numbers=False, no_numbers=False, no_currency_symbols=False, no_punct=False, no_contractions=False, no_accents=False)\n",
      "    Normalize various aspects of a raw text doc before parsing it with Spacy.\n",
      "    A convenience function for applying all other preprocessing functions in one go.\n",
      "    \n",
      "    Args:\n",
      "        text (str): raw text to preprocess\n",
      "        fix_unicode (bool): if True, fix \"broken\" unicode such as\n",
      "            mojibake and garbled HTML entities\n",
      "        lowercase (bool): if True, all text is lower-cased\n",
      "        transliterate (bool): if True, convert non-ascii characters\n",
      "            into their closest ascii equivalents\n",
      "        no_urls (bool): if True, replace all URL strings with '*URL*'\n",
      "        no_emails (bool): if True, replace all email strings with '*EMAIL*'\n",
      "        no_phone_numbers (bool): if True, replace all phone number strings\n",
      "            with '*PHONE*'\n",
      "        no_numbers (bool): if True, replace all number-like strings\n",
      "            with '*NUMBER*'\n",
      "        no_currency_symbols (bool): if True, replace all currency symbols\n",
      "            with their standard 3-letter abbreviations\n",
      "        no_punct (bool): if True, remove all punctuation (replace with\n",
      "            empty string)\n",
      "        no_contractions (bool): if True, replace *English* contractions\n",
      "            with their unshortened forms\n",
      "        no_accents (bool): if True, replace all accented characters\n",
      "            with unaccented versions; NB: if `transliterate` is True, this option\n",
      "            is redundant\n",
      "    \n",
      "    Returns:\n",
      "        str: input ``text`` processed according to function args\n",
      "    \n",
      "    Warning:\n",
      "        These changes may negatively affect subsequent NLP analysis performed\n",
      "        on the text, so choose carefully, and preprocess at your own risk!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(textacy.preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除此之外，textacy通过`textacy.Doc`的方式，能够<b>自动检测加载文本的语言</b>。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Tom is happily running in the park'\n",
    "doc = textacy.Doc(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(textacy.Doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此外，还提供词性正则表达式的功能，可以方便获取想要的短语组合："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tom is happily running']\n"
     ]
    }
   ],
   "source": [
    "pattern = r'(<NOUN|PROPN>+<VERB>+<DET>?<ADV>*<VERB>+)'\n",
    "phraselist = list(textacy.extract.pos_regex_matches(doc, pattern))\n",
    "print([phrase.text for phrase in phraselist])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "textacy的github地址：[textacy: NLP, before and after spaCy](https://github.com/chartbeat-labs/textacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/textacygithub.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "官方说明文档: [textacy: NLP, before and after spaCy](https://chartbeat-labs.github.io/textacy/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/textacytutorial.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK是一个高效的Python构建的平台，用来处理人类自然语言数据。它提供了易于使用的接口，通过这些接口可以访问超过50个语料库和词汇资源（如WordNet），还有一套用于分类、标记化、词干标记、解析和语义推理的文本处理库，以及工业级NLP库的封装器和一个活跃的讨论论坛。\n",
    "\n",
    "统计语言学话题方面的手动编程指南加上全面的API文档，使得NLTK非常适用于语言学家、工程师、学生、教育家、研究人员以及行业用户等人群。NLTK可以在Windows、Mac OS X以及Linux系统上使用。最好的一点是，NLTK是一个免费、开源的社区驱动的项目。\n",
    "\n",
    "NLTK被称为“一个使用Python开发的用于统计语言学的教学和研究的有利工具”和“一个自然语言处理的高效库”。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相比Spacy之类的自然语言处理包，NLTK有一些偏学术化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Github地址：[NLTK](https://github.com/nltk/nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "官方地址：[NLTK](https://www.nltk.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 JIEBA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jieba（结巴）是一个强大的分词库，完美支持中文分词。\n",
    "\n",
    "一般来说中文文本不会如同拉丁语系一样，词与词之间有明显的空格作为间隔。\n",
    "\n",
    "如果需要对中文文本建模，那么分词是必须的前提条件，那么Jieba就是目前为止最好的中文分词组件包。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其优点有：\n",
    "\n",
    "1 支持三种分词模式：\n",
    "\n",
    "a. 精确模式，试图将句子最精确地切开，适合文本分析；\n",
    "\n",
    "b. 全模式，把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义；\n",
    "\n",
    "c. 搜索引擎模式，在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。\n",
    "\n",
    "2 支持自定义词典"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面来看看如何对中文做分词："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 精准模式\n",
    "\n",
    "试图将句子最精确地切开,适合文本分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "text = r'小张毕业于深圳大学，这座大学位于南山区'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\bhe\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.194 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "小张/毕业/于/深圳大学/，/这座/大学/位于/南山区\n"
     ]
    }
   ],
   "source": [
    "words = jieba.cut(text)\n",
    "print('/'.join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把句子中所有的可以成词的词语都扫描出来, 速度非常快,但是不能解决歧义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "小张/毕业/于/深圳/深圳大学/大学///这/座/大学/学位/位于/南山/南山区/山区\n"
     ]
    }
   ],
   "source": [
    "words = jieba.cut(text, cut_all=True)\n",
    "print('/'.join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 搜索引擎模式\n",
    "\n",
    "在精确模式的基础上,对长词再次切分,提高召回率,适合用于搜索引擎分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "小张/毕业/于/深圳/大学/深圳大学/，/这座/大学/位于/南山/山区/南山区\n"
     ]
    }
   ],
   "source": [
    "output = jieba.cut_for_search(text)\n",
    "print('/'.join(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词性标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "单词：小张, 词性：n\n",
      "单词：毕业, 词性：n\n",
      "单词：于, 词性：p\n",
      "单词：深圳大学, 词性：nt\n",
      "单词：，, 词性：x\n",
      "单词：这, 词性：r\n",
      "单词：座, 词性：q\n",
      "单词：大学, 词性：n\n",
      "单词：位于, 词性：v\n",
      "单词：南山区, 词性：ns\n"
     ]
    }
   ],
   "source": [
    "import jieba.posseg as pseg\n",
    "words = pseg.cut(text)\n",
    "for word, flag in words:\n",
    "    print('单词：{0}, 词性：{1}'.format(word, flag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 关键词提取\n",
    "\n",
    "Jieba的关键词提取功能，是基于TF-IDF算法的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "竞技  马德里  欧冠  联赛  球队  一役  西蒙尼  18  26  场均  丢球数  引援  四场  威斯特法伦  上赛季  那样  取得  巴萨  似乎  出线\n"
     ]
    }
   ],
   "source": [
    "import jieba.analyse as analyse\n",
    "text = \"\"\"欧冠提前一轮出线，近四场比赛取得3胜1平，距离终结联赛对巴萨的不胜纪录也只有一步之遥，\n",
    "马德里竞技似乎已经完全从惨败威斯特法伦一役的阴霾中走了出来。\n",
    "球队近来的成绩有所提升，但困扰西蒙尼的战术难题并没有得到解决，\n",
    "马德里竞技要取得一场的胜利似乎总是要付出比其他球队更多的努力，双线战场18战仅仅打入26球，\n",
    "场均丢球数却达到了数年来的峰值，联赛中的两大竞争对手均状态不佳，欧冠分组也十分有利，\n",
    "但马德里竞技依然没能如人们预期的那样脱颖而出，更为尴尬的是，\n",
    "他们此次已经不能像上赛季那样以引援不力作为借口了。\"\"\"\n",
    "print(\"  \".join(analyse.extract_tags(text, topK=20, withWeight=False, allowPOS=())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 常用模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 TF/ IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF（term frequency–inverse document frequency）是一种用于资讯检索与资讯探勘的常用加权技术。\n",
    "   \n",
    "TF-IDF是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。\n",
    "   \n",
    "<b>字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。</b>\n",
    "   \n",
    "TF-IDF加权的各种形式常被搜寻引擎应用，作为文件与用户查询之间相关程度的度量或评级。\n",
    "   \n",
    "除了TF-IDF以外，因特网上的搜寻引擎还会使用基于连结分析的评级方法，以确定文件在搜寻结果中出现的顺序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在一份给定的文件里，<b>词频 (term frequency, TF)</b> 指的是某一个给定的词语在该文件中出现的次数。这个数字通常会被归一化（分子一般小于分母 区别于IDF），以防止它偏向长的文件。（同一个词语在长文件里可能会比短文件有更高的词频，而不管该词语重要与否。）\n",
    "\n",
    "<b>逆向文件频率 (inverse document frequency, IDF)</b> 是一个词语普遍重要性的度量。某一特定词语的IDF，可以由总文件数目除以包含该词语之文件的数目，再将得到的商取对数得到。\n",
    "\n",
    "某一特定文件内的高词语频率，以及该词语在整个文件集合中的低文件频率，可以产生出高权重的TF-IDF。因此，TF-IDF倾向于过滤掉常见的词语，保留重要的词语。\n",
    "\n",
    "<b>TF-IDF的主要思想是：</b>\n",
    "\n",
    "如果某个词或短语在一篇文章中出现的频率TF高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。\n",
    "\n",
    "TF-IDF实际上是：TF * IDF，TF词频(Term Frequency)，IDF反文档频率(Inverse Document Frequency)。\n",
    "\n",
    "TF表示词条在文档d中出现的频率（另一说：TF词频(Term Frequency)指的是某一个给定的词语在该文件中出现的次数）。\n",
    "\n",
    "IDF的主要思想是：如果包含词条t的文档越少，也就是n越小，IDF越大，则说明词条t具有很好的类别区分能力。\n",
    "\n",
    "如果某一类文档C中包含词条t的文档数为m，而其它类包含t的文档总数为k，显然所有包含t的文档数n=m+k，当m大的时候，n也大，按照IDF公式得到的IDF的值会小，就说明该词条t类别区分能力不强。\n",
    "\n",
    "（另一说：IDF反文档频率(Inverse Document Frequency)是指果包含词条的文档越少，IDF越大，则说明词条具有很好的类别区分能力。）\n",
    "\n",
    "但是实际上，如果一个词条在一个类的文档中频繁出现，则说明该词条能够很好代表这个类的文本的特征，这样的词条应该给它们赋予较高的权重，并选来作为该类文本的特征词以区别与其它类文档。这就是IDF的不足之处."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最简单的直观公式："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/tf1.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/idf.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/tfidf.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学术一些的公式如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/tfidf_math.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "维基百科的地址:[tf-idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例见本文的：3.3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 与余弦相似度的结合应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "余弦相似度的维基百科定义：[Cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比如两个句子：\n",
    "\n",
    "句子A: 我喜欢看电视，不喜欢看电影。\n",
    "\n",
    "句子B: 我不喜欢看电视，也不喜欢看电影。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 经过分词与计算词频：\n",
    "\n",
    "句子A：我 1，喜欢 2，看 2，电视 1，电影 1，不 1，也 0。\n",
    "\n",
    "句子B：我 1，喜欢 2，看 2，电视 1，电影 1，不 2，也 1。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 写出词频向量\n",
    "\n",
    "句子A：[1, 2, 2, 1, 1, 1, 0]\n",
    "\n",
    "句子B：[1, 2, 2, 1, 1, 2, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到这里，问题就变成了如何计算这两个向量的相似程度。\n",
    "\n",
    "我们可以把它们想象成空间中的两条线段，都是从原点（[0, 0, ...]）出发，指向不同的方向。\n",
    "\n",
    "两条线段之间形成一个夹角，如果夹角为0度，意味着方向相同、线段重合；如果夹角为90度，意味着形成直角，方向完全不相似；如果夹角为180度，意味着方向正好相反。\n",
    "\n",
    "因此，我们可以通过夹角的大小，来判断向量的相似程度。夹角越小，就代表越相似。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/cos1.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以二维空间为例，上图的a和b是两个向量，我们要计算它们的夹角θ。余弦定理告诉我们，可以用下面的公式求得："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/cos2.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/cos3.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假定a向量是[x1, y1]，b向量是[x2, y2]，那么可以将余弦定理改写成下面的形式："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/cos4.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/cos5.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数学家已经证明，余弦的这种计算方法对n维向量也成立。假定A和B是两个n维向量，A是 [A1, A2, ..., An] ，B是 [B1, B2, ..., Bn] ，则A与B的夹角θ的余弦等于："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/cos6.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用这个公式，我们就可以得到，句子A与句子B的夹角的余弦。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/cos7.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "余弦值越接近1，就表明夹角越接近0度，也就是两个向量越相似，这就叫\"余弦相似性\"。\n",
    "\n",
    "所以，上面的句子A和句子B是很相似的，事实上它们的夹角大约为20.3度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.4 找出相似文章的简易算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）使用TF-IDF算法，找出两篇文章的关键词；\n",
    "\n",
    "（2）每篇文章各取出若干个关键词（比如20个），合并成一个集合，计算每篇文章对于这个集合中的词的词频（为了避免文章长度的差异，可以使用相对词频）；\n",
    "\n",
    "（3）生成两篇文章各自的词频向量；\n",
    "\n",
    "（4）计算两个向量的余弦相似度，值越大就表示越相似。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 词向量（Word2Vec）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自然语言处理的词频处理方法即TF-IDF，这种方法往往只是可以找出一篇文章中比较关键的词语，即找出一些主题词汇。\n",
    "\n",
    "但无法给出词汇的语义，比如同义词漂亮和美丽意思差不多应该相近，巴黎之于法国等同于北京之于中国。\n",
    "\n",
    "对于一句话，如何根据上下文推断出中间的词语是什么，或者由某一个词推测出它的上下文一般是什么词语。\n",
    "\n",
    "这两种不同的思考方式正好对应两种Word2vec模型，即CBOW模型和Skip-gram模型。\n",
    "\n",
    "所谓的word vector，就是指将单词向量化，将某个单词用特定的向量来表示。\n",
    "\n",
    "将单词转化成对应的向量以后，就可以将其应用于各种机器学习的算法中去。\n",
    "\n",
    "\n",
    "一般来讲，词向量主要有两种形式，分别是稀疏向量和密集向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>所谓稀疏向量</b>，又称为one-hot representation，就是用一个很长的向量来表示一个词，向量的长度为词典的大小N，向量的分量只有一个1，其他全为0，1的位置对应该词在词典中的索引[1]。\n",
    "\n",
    "举例来说，如果有一个词典[“面条”,”方便面”,”狮子”]，那么“面条”对应的词向量就是[1,0,0]，“方便面”对应的词向量就是[0,1,0]。这种表示方法不需要繁琐的计算，简单易得，但是缺点也不少，比如长度过长（这会引发维数灾难），以及无法体现出近义词之间的关系，比如“面条”和“方便面”显然有非常紧密的关系，但转化成向量[1,0,0]和[0,1,0]以后，就看不出两者有什么关系了,因为这两个向量相互正交。\n",
    "\n",
    "当然了，用这种稀疏向量求和来表示文档向量效果还不错，清华的长文本分类工具THUCTC使用的就是此种表示方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>密集向量</b>，又称distributed representation，即分布式表示。最早由Hinton提出，可以克服one-hot representation的上述缺点。\n",
    "\n",
    "基本思路是通过训练将每个词映射成一个固定长度的短向量，所有这些向量就构成一个词向量空间，每一个向量可视为该空间上的一个点[1]。\n",
    "\n",
    "此时向量长度可以自由选择，与词典规模无关。这是非常大的优势。\n",
    "\n",
    "还是用之前的例子[“面条”,”方便面”,”狮子”]，经过训练后，“面条”对应的向量可能是[1,0,1,1,0],而“方便面”对应的可能是[1,0,1,0,0]，而“狮子”对应的可能是[0,1,0,0,1]。\n",
    "\n",
    "这样“面条”向量乘“方便面”=2，而“面条”向量乘“狮子”=0 。这样就体现出面条与方便面之间的关系更加紧密，而与狮子就没什么关系了。这种表示方式更精准的表现出近义词之间的关系，比之稀疏向量优势很明显。可以说这是深度学习在NLP领域的第一个运用（虽然我觉得并没深到哪里去）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 Skip-gram和CBOW模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Skip-gram：如果是用一个词语作为输入，来预测它周围的上下文，那这个模型叫做『Skip-gram 模型』"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/skipgram.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看成是 单个x->单个y 模型的并联，cost function 是单个 cost function 的累加（取log之后）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CBOW：如果是拿一个词语的上下文作为输入，来预测这个词语本身，则是 『CBOW 模型』"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/cbow.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与Skip-gram 的模型并联不同，这里是输入变成了多个单词，所以要对输入处理下（一般是求和然后平均），输出的 cost function不变"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3 Skip-gram与CBOW的对比 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CBOW是以周围词作为输入，中心词作为目标的网络，所以假设一篇语料中有V个单词，那么CBOW将会以每一个单词作为中心词进行训练，因此会有V次\n",
    "\n",
    "Skip-gram是以中心词作为输入，周围词作为目标的网络，那么对于一篇语料来说，每一个词都会作为中心词，每个中心词周围大小选择K个，那么将会进行KV次\n",
    "\n",
    "直观上来看，CBOW训练次数要比skip-gram少，也即精确率不如skip-gram,但是效率高，速度快。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3 实例演示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用Text8Corpus做演示，这个语料库是英文的，大小不到100M。下载地址为:[Text8Zip](http://mattmahoney.net/dc/text8.zip )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "考虑到文件有些大， 就不传到github了，大家自行下载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练及加载模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.models import word2vec\n",
    "import os\n",
    "folder = r'./nlpmodel/text8'\n",
    "modelfile = os.path.join(folder, 'text8.w2v.model')\n",
    "if os.path.exists(modelfile):\n",
    "    # 将硬盘中的模型载入\n",
    "    model = KeyedVectors.load(modelfile)\n",
    "else:\n",
    "    # 使用一个很小的英文语料\n",
    "    # 下载地址 http://mattmahoney.net/dc/text8.zip \n",
    "    sentences = word2vec.Text8Corpus(os.path.join(folder, 'text8'))\n",
    "    # Gensim的word2vec的训练模式由参数sg决定，0: CBOW，1: skip-gram，默认为CBOW\n",
    "    model = word2vec.Word2Vec(sentences, size=200, window=5, min_count=5)\n",
    "    # 设置向量为200维，窗口大小为5，忽略掉词频低于5的词\n",
    "    # 经过一段时间的等待，就训练完成了。\n",
    "    # 将训练好的模型保存到硬盘，文件名随意\n",
    "    model.save(os.path.join(folder, 'text8.w2v.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个例子是非常经典的，根据positive: worman, king, negative: man，推断出最相近的词是queen的例子\n",
    "\n",
    "其意义是计算一个词d（或者词表），使得该词的向量v(d)与v(a=\"woman\")-v(c=\"man\")+v(b=\"king\")最近"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python36\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "d:\\python36\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.6738182306289673), ('throne', 0.575992226600647), ('empress', 0.5739238262176514), ('princess', 0.5734347105026245), ('elizabeth', 0.5587899684906006), ('daughter', 0.555698037147522), ('jadwiga', 0.5538528561592102), ('prince', 0.5492069721221924), ('isabella', 0.545307457447052), ('consort', 0.541345477104187)]\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar(positive=[\"woman\",\"king\"],negative=[\"man\"],topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \n",
      "d:\\python36\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6278037\n"
     ]
    }
   ],
   "source": [
    "# 计算两个词的相似度\n",
    "print(model.similarity('mobile', 'phone'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n",
      "d:\\python36\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bad', 0.7257406711578369), ('poor', 0.5354788303375244), ('safe', 0.5291586518287659), ('quick', 0.5234116911888123), ('luck', 0.5217357873916626), ('reasonable', 0.5067963004112244), ('simple', 0.49832555651664734), ('really', 0.492895245552063), ('you', 0.48568713665008545), ('happy', 0.4837035536766052), ('silly', 0.4836675524711609), ('fun', 0.4832077622413635), ('pleasant', 0.4797707796096802), ('my', 0.4790000915527344), ('fast', 0.4784563183784485), ('easy', 0.4768497943878174), ('helpful', 0.47399526834487915), ('practical', 0.4722078740596771), ('your', 0.4720571041107178), ('little', 0.4691823422908783)]\n"
     ]
    }
   ],
   "source": [
    "# 寻找和某个词最相似的词（会输出词和相似度打分，本以为这个如果自己实现的话会很复杂，竟然在包里就提供了相关方法）\n",
    "print(model.most_similar('good', topn=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  \n",
      "d:\\python36\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cereal\n"
     ]
    }
   ],
   "source": [
    "# 识别不合群的词\n",
    "print(model.doesnt_match('breakfast cereal dinner lunch'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anarchism\n",
      "originated\n",
      "as\n",
      "a\n",
      "term\n",
      "of\n",
      "abuse\n",
      "first\n",
      "used\n",
      "against\n",
      "early\n",
      "working\n",
      "class\n",
      "radicals\n",
      "including\n",
      "the\n",
      "diggers\n",
      "english\n",
      "revolution\n",
      "and\n",
      "sans\n",
      "culottes\n",
      "french\n",
      "whilst\n",
      "is\n",
      "still\n",
      "in\n",
      "pejorative\n",
      "way\n",
      "to\n",
      "describe\n",
      "any\n",
      "act\n",
      "that\n",
      "violent\n",
      "means\n",
      "destroy\n",
      "organization\n",
      "society\n",
      "it\n",
      "has\n",
      "also\n",
      "been\n",
      "taken\n",
      "up\n",
      "positive\n",
      "label\n",
      "by\n",
      "self\n",
      "defined\n",
      "anarchists\n",
      "word\n",
      "derived\n",
      "from\n",
      "greek\n",
      "without\n",
      "archons\n",
      "ruler\n",
      "chief\n",
      "king\n",
      "political\n",
      "philosophy\n",
      "belief\n",
      "rulers\n",
      "are\n",
      "unnecessary\n",
      "should\n",
      "be\n",
      "abolished\n",
      "although\n",
      "there\n",
      "differing\n",
      "interpretations\n",
      "what\n",
      "this\n",
      "refers\n",
      "related\n",
      "social\n",
      "movements\n",
      "advocate\n",
      "elimination\n",
      "authoritarian\n",
      "institutions\n",
      "particularly\n",
      "state\n",
      "anarchy\n",
      "most\n",
      "use\n",
      "does\n",
      "not\n",
      "imply\n",
      "chaos\n",
      "nihilism\n",
      "or\n",
      "anomie\n",
      "but\n",
      "rather\n",
      "harmonious\n",
      "anti\n",
      "place\n",
      "regarded\n",
      "structures\n",
      "71290\n"
     ]
    }
   ],
   "source": [
    "# 获得词典中的词\n",
    "for index, key in enumerate(model.wv.vocab.keys()):\n",
    "    print(key)\n",
    "    if index > 100:\n",
    "        break\n",
    "print(len(model.wv.vocab.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 文档向量 （Doc2Vec）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 Doc2Vec原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc2Vec 或者叫做 paragraph2vec, sentence embeddings，是一种非监督式算法，可以获得sentences/paragraphs/documents 的向量表达，是 word2vec 的拓展，Doc2Vec的目的是获得文档的一个固定长度的向量表达, 即向量索引是以Doc为单位，而不是以Word为单位。\n",
    "\n",
    "学出来的向量可以通过计算距离来找 sentences/paragraphs/documents 之间的相似性， 或者进一步可以给文档打标签。\n",
    "\n",
    "例如首先是找到一个向量可以代表文档的意思，然后可以将向量投入到监督式机器学习算法中得到文档的标签， 例如在情感分析sentiment analysis 任务中，标签可以是 “negative”, “neutral”,”positive”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc2Vec也有两种方式来实现："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>DBOW (distributed bag of words)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/DBOW.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>DM(distributed memory)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/DM.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实战示例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假定有表示文档分类的样本集，如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2060 Retirement Fund, Vanguard Variable Insura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Effective May 1, 2018, the following funds wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Effective on or after May 1, 2018, the followi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Effective on or after May 1, 2018, the followi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The following Investment Options will be avail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>The following portfolio has been added as an a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>This fund is available beginning 06/11/2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>This fund will be available on or about May 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>This fund will be available on or around May 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>Effective August 13, 2018, the Investment Divi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>FORMER FUND NAME MERGED FUND NAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>Emerging Growth Portfolio merged into The Trav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>Effective on or about 05/01/06, Capital Apprec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>Effective on or about 05/01/06, The Travelers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>Effective on or about 05/01/06, The Travelers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>Effective on or about 05/01/06, Capital Apprec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>AIM V.I. Premier Equity Fund merged into AIM V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>Effective on or about 05/01/06, The Travelers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>All Cap Growth Portfolio merged into Legg Maso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>AIM V.I. Premier Equity Fund merged into AIM V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>The Travelers Series Trust MFS(R) Value Portfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>MERGERSThe following former Underlying Funds m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>MERGED UNDERLYING FUND/TRUST SURVIVING UNDERLY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>Travelers Series Trust Managed Allocation Seri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>On March 15, 2018, the Board of Trustees of Vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>HIMCO VIT INDEX FUND CLASS IB (MERGED INTO BLA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>As previously supplemented on February 28, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>Subject to shareholder approval, effective aft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>This fund will be liquidating on or about June...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>any Fund is liquidated then your allocations t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5</td>\n",
       "      <td>Fund variable investment option (the \"Investme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5</td>\n",
       "      <td>LIQUIDATED AND INVESTED IN INVESCO V.I. GOVERN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5</td>\n",
       "      <td>— — — — — — *CTIVP SM – Eaton Vance Floating R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5</td>\n",
       "      <td>3,003 2,601 2,169 2,225 1,859 759 232 55 — — *...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5</td>\n",
       "      <td>*CTIVP SM – Eaton Vance Floating Rate Income F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5</td>\n",
       "      <td>Accumulation unit value at beginning of period...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>Effective May 1, 2018, no new premium payment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>We no longer accept new applications for this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>Effective May 1, 2018, the Long/Short Large Ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category                                           sentence\n",
       "0          1  2060 Retirement Fund, Vanguard Variable Insura...\n",
       "1          1  Effective May 1, 2018, the following funds wil...\n",
       "2          1  Effective on or after May 1, 2018, the followi...\n",
       "3          1  Effective on or after May 1, 2018, the followi...\n",
       "4          1  The following Investment Options will be avail...\n",
       "5          1  The following portfolio has been added as an a...\n",
       "6          1       This fund is available beginning 06/11/2018)\n",
       "7          1  This fund will be available on or about May 21...\n",
       "8          1  This fund will be available on or around May 2...\n",
       "9          3  Effective August 13, 2018, the Investment Divi...\n",
       "10         4                  FORMER FUND NAME MERGED FUND NAME\n",
       "11         4  Emerging Growth Portfolio merged into The Trav...\n",
       "12         4  Effective on or about 05/01/06, Capital Apprec...\n",
       "13         4  Effective on or about 05/01/06, The Travelers ...\n",
       "14         4  Effective on or about 05/01/06, The Travelers ...\n",
       "15         4  Effective on or about 05/01/06, Capital Apprec...\n",
       "16         4  AIM V.I. Premier Equity Fund merged into AIM V...\n",
       "17         4  Effective on or about 05/01/06, The Travelers ...\n",
       "18         4  All Cap Growth Portfolio merged into Legg Maso...\n",
       "19         4  AIM V.I. Premier Equity Fund merged into AIM V...\n",
       "20         4  The Travelers Series Trust MFS(R) Value Portfo...\n",
       "21         4  MERGERSThe following former Underlying Funds m...\n",
       "22         4  MERGED UNDERLYING FUND/TRUST SURVIVING UNDERLY...\n",
       "23         4  Travelers Series Trust Managed Allocation Seri...\n",
       "24         4  On March 15, 2018, the Board of Trustees of Vo...\n",
       "25         4  HIMCO VIT INDEX FUND CLASS IB (MERGED INTO BLA...\n",
       "26         4  As previously supplemented on February 28, 201...\n",
       "27         4  Subject to shareholder approval, effective aft...\n",
       "28         5  This fund will be liquidating on or about June...\n",
       "29         5  any Fund is liquidated then your allocations t...\n",
       "30         5  Fund variable investment option (the \"Investme...\n",
       "31         5  LIQUIDATED AND INVESTED IN INVESCO V.I. GOVERN...\n",
       "32         5  — — — — — — *CTIVP SM – Eaton Vance Floating R...\n",
       "33         5  3,003 2,601 2,169 2,225 1,859 759 232 55 — — *...\n",
       "34         5  *CTIVP SM – Eaton Vance Floating Rate Income F...\n",
       "35         5  Accumulation unit value at beginning of period...\n",
       "36         2  Effective May 1, 2018, no new premium payment ...\n",
       "37         2  We no longer accept new applications for this ...\n",
       "38         2  Effective May 1, 2018, the Long/Short Large Ca..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "doc2vecmodelrawtextpath = './nlpmodel/vacategorymodelrawtext.csv'\n",
    "rawdata = pd.read_csv(doc2vecmodelrawtextpath, encoding='utf-16', sep='\\t')\n",
    "display(rawdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面来看一下，如何将这个样本集训练为Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备工作：\n",
    "- 将数据集进行文本清洗\n",
    "- 将数据集进行Tag处理\n",
    "- 需要注意的是：Tag由下划线分隔，下划线左边为样本的索引，下划线右边为样本的category，如：1: Added, 2: Closed, 3: Reopen, 4: Merged, 5: Liquidation\n",
    "- <b>如果Tag按照这种方式进行处理，即达到利用无监督的方式，实现有监督的目的</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdatasetfordoc2vector(file):\n",
    "    print('Get doc list begin')\n",
    "    rawdata = pd.read_csv(file, encoding='utf-16', sep='\\t')\n",
    "    rawdoclist = rawdata['sentence']\n",
    "    rawdata['cleantext'] = rawdata['sentence'].apply(lambda x: cleardatafordoc2vector(x))\n",
    "    rawdata['category'] = rawdata['category'].apply(int)\n",
    "    x_train = []\n",
    "    for index, row in rawdata.iterrows():\n",
    "        word_list = rawdata.loc[index, 'cleantext'].lower().strip().split()\n",
    "        if len(word_list) == 0:\n",
    "            word_list = ['only', 'for', 'test']\n",
    "        tagtype = rawdata.loc[index, 'category']\n",
    "        if not tagtype:\n",
    "            tagtype = 0\n",
    "        document = TaggedDocument(word_list, tags=['{0}_{1}'.format(index, tagtype)])\n",
    "        x_train.append(document)\n",
    "    print('Get doc list end')\n",
    "    return x_train, rawdoclist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练数据集的主方法体：\n",
    "\n",
    "- 清洗样本\n",
    "- 对样本进行训练，生成Doc2Vec模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traindoc2vec(rawtextfile,\n",
    "                 modelfolder,\n",
    "                 modelfilename,\n",
    "                 vector_size=200,\n",
    "                 epoch_num=10,\n",
    "                 needregenerate=True):\n",
    "    x_train, rawdoclist = getdatasetfordoc2vector(rawtextfile)\n",
    "    model_dm = doc2vectortrain(modelfolder,\n",
    "                               modelfilename,\n",
    "                               x_train,\n",
    "                               vector_size=vector_size,\n",
    "                               epoch_num=epoch_num,\n",
    "                               needregenerate=needregenerate)\n",
    "    return x_train, rawdoclist, model_dm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练样本为Doc2Vec模型的方法体：\n",
    "\n",
    "- 注意默认的训练次数为30\n",
    "- 特征向量维度为200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2vectortrain(folder, filename, x_train, vector_size=200, epoch_num=30, needregenerate=False):\n",
    "    print('Train Doc2Vector begin')\n",
    "    modelfilepath = os.path.join(folder, filename)\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    if needregenerate or not os.path.exists(modelfilepath):\n",
    "        model_dm = Doc2Vec(x_train, min_count=1, window=3, vector_size=vector_size, sample=1e-3, negative=5, workers=2)\n",
    "        model_dm.train(x_train, total_examples=model_dm.corpus_count, epochs=epoch_num)\n",
    "        model_dm.save(modelfilepath)\n",
    "    else:\n",
    "        model_dm = Doc2Vec.load(modelfilepath)\n",
    "    print('Train Doc2Vector end')\n",
    "    return model_dm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get doc list begin\n",
      "Get doc list end\n",
      "Train Doc2Vector begin\n",
      "Train Doc2Vector end\n"
     ]
    }
   ],
   "source": [
    "rawtextfile = './nlpmodel/vacategorymodelrawtext.csv'\n",
    "modelfolder = './nlpmodel'\n",
    "modelfilename = 'vadoccategorydoc2vec.model'\n",
    "x_train, rawdoclist, model_dm = traindoc2vec(rawtextfile,\n",
    "                                             modelfolder,\n",
    "                                             modelfilename,\n",
    "                                             vector_size=100,\n",
    "                                             epoch_num=5000,\n",
    "                                             needregenerate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化样本集以及Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vecmodel = None\n",
    "alltext = None\n",
    "doc2vecmodelrawtextpath = './nlpmodel/vacategorymodelrawtext.csv'\n",
    "doc2vecmodelpath = './nlpmodel/vadoccategorydoc2vec.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialdoc2vecmodel(alltextpath=doc2vecmodelrawtextpath, doc2vecmodelpath=doc2vecmodelpath):\n",
    "    print(\"load text begin\")\n",
    "    global alltext\n",
    "    if alltext is None:\n",
    "        rawdata = pd.read_csv(alltextpath, encoding='utf-16', sep='\\t')\n",
    "        alltext = rawdata['sentence']\n",
    "    print(\"load text end\")\n",
    "\n",
    "    print(\"load doc2vec model begin\")\n",
    "    global doc2vecmodel\n",
    "    if doc2vecmodel is None:\n",
    "        doc2vecmodel = Doc2Vec.load(doc2vecmodelpath)\n",
    "    print(\"load doc2vec model end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据Model以及样本数据，获得inver_vector列表 (Infer a vector for given post-bulk training document(为给定的批量后培训文档推断一个向量))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdoc2vec_inferedvectorlist(doc2vecmodelpath, x_train):\n",
    "    infered_vectors_list = []\n",
    "    print(\"load doc2vec model begin\")\n",
    "    model_dm = Doc2Vec.load(doc2vecmodelpath)\n",
    "    print(\"load doc2vec model end\")\n",
    "\n",
    "    print(\"load train vectors begin\")\n",
    "    for text, label in x_train:\n",
    "        vector = model_dm.infer_vector(text)\n",
    "        infered_vectors_list.append(vector)\n",
    "    print(\"load train vectors end\")\n",
    "    return infered_vectors_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方法体：根据给定的sentence以及Doc2Vec model，获得相似度最高的前10个句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getmostsimilaritybydoc2vec(sentence):\n",
    "    global alltext\n",
    "    global doc2vecmodel\n",
    "    if alltext is None or doc2vecmodel is None:\n",
    "        initialdoc2vecmodel()\n",
    "    test_cut = cleardatafordoc2vector(sentence).split()\n",
    "    inferred_vector = doc2vecmodel.infer_vector(test_cut)\n",
    "    simsbow = doc2vecmodel.docvecs.most_similar([inferred_vector], topn=10)\n",
    "    return getcontent(sentence, simsbow, alltext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcontent(rawsentence, simsbow, doclist):\n",
    "    similarresult = {'rawsentence': rawsentence, 'similarlist': []}\n",
    "    for i in simsbow:\n",
    "        similardict = {}\n",
    "        similar = doclist[int(i[0].split('_')[0])]\n",
    "        similardict['paraid'] = i[0]\n",
    "        similardict['similarity'] = i[1]\n",
    "        similardict['paracontent'] = similar\n",
    "        similarresult['similarlist'].append(similardict)\n",
    "    return similarresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load text begin\n",
      "load text end\n",
      "load doc2vec model begin\n",
      "load doc2vec model end\n"
     ]
    }
   ],
   "source": [
    "initialdoc2vecmodel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：根据给定的sentence以及Doc2Vec model，获得相似度最高的前10个句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python36\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################\n",
      "raw sentence is: \n",
      "CTIVP SM – Eaton Vance Floating Rate Income Fund (Class 2) liquidated on April 27, 2018.\n",
      "###############################\n",
      "\n",
      "paragraph id: 32_5, similarity: 0.9833414554595947\n",
      "paragraph is:\n",
      "— — — — — — *CTIVP SM – Eaton Vance Floating Rate Income Fund (Class 2) liquidated on April 27, 2018.\n",
      "###############################\n",
      "paragraph id: 34_5, similarity: 0.982774555683136\n",
      "paragraph is:\n",
      "*CTIVP SM – Eaton Vance Floating Rate Income Fund (Class 2) liquidated on April 27, 2018.\n",
      "###############################\n",
      "paragraph id: 33_5, similarity: 0.9814426302909851\n",
      "paragraph is:\n",
      "3,003 2,601 2,169 2,225 1,859 759 232 55 — — *CTIVP SM – Eaton Vance Floating Rate Income Fund (Class 2) liquidated on April 27, 2018.\n",
      "###############################\n",
      "paragraph id: 35_5, similarity: 0.7010773420333862\n",
      "paragraph is:\n",
      "Accumulation unit value at beginning of period $1.08 $1.00 $1.03 $1.05 $1.03 $1.00 Accumulation unit value at end of period $1.09 $1.08 $1.00 $1.03 $1.05 $1.03 Number of accumulation units outstanding at end of period (000 omitted) 10 10 55 57 60 — *CTIVP SM – Eaton Vance Floating Rate Income Fund (Class 2) liquidated on April 27, 2018.\n",
      "###############################\n",
      "paragraph id: 31_5, similarity: 0.640414834022522\n",
      "paragraph is:\n",
      "LIQUIDATED AND INVESTED IN INVESCO V.I. GOVERNMENT MONEY MARKET FUND ON 04/27/2018)\n",
      "###############################\n",
      "paragraph id: 25_4, similarity: 0.6275163888931274\n",
      "paragraph is:\n",
      "HIMCO VIT INDEX FUND CLASS IB (MERGED INTO BLACKROCK S&P 500 INDEX V.I. FUND ON 04/20/2018; REORGANIZED FROM HARTFORD INDEX HLS FUND ON 10/20/2014) UNIT VALUE: Beginning of Period $ 12.128 $ 10.981 $ 10.979\n",
      "###############################\n",
      "paragraph id: 28_5, similarity: 0.6186009049415588\n",
      "paragraph is:\n",
      "This fund will be liquidating on or about June 28, 2018.\n",
      "###############################\n",
      "paragraph id: 17_4, similarity: 0.5357693433761597\n",
      "paragraph is:\n",
      "Effective on or about 05/01/06, The Travelers Series Trust Pioneer Strategic Income Portfolio merged into Met Investors Series Trust Pioneer Strategic Income Portfolio and is no longer available as a funding option.\n",
      "###############################\n",
      "paragraph id: 14_4, similarity: 0.5356754064559937\n",
      "paragraph is:\n",
      "Effective on or about 05/01/06, The Travelers Series Trust Mondrian International Stock Portfolio merged into Met Investors Series Trust Harris Oakmark International Portfolio and is no longer available as a funding option.\n",
      "###############################\n",
      "paragraph id: 12_4, similarity: 0.5340012311935425\n",
      "paragraph is:\n",
      "Effective on or about 05/01/06, Capital Appreciation Fund merged into Met Investors Series Trust Janus Capital Appreciation Portfolio and is no longer available as a funding option.\n",
      "###############################\n"
     ]
    }
   ],
   "source": [
    "# sentence = r'Effective May 1, 2018, the following funds will be available as new investment options under your Policy.'\n",
    "# sentence = r'Fund variable investment option (the \"Investment Option\") will be liquidated.'\n",
    "sentence = r'CTIVP SM – Eaton Vance Floating Rate Income Fund (Class 2) liquidated on April 27, 2018.'\n",
    "result = getmostsimilaritybydoc2vec(sentence)\n",
    "print('###############################')\n",
    "print('raw sentence is: ')\n",
    "print(result['rawsentence'])\n",
    "print('###############################')\n",
    "print()\n",
    "for similar in result['similarlist']:\n",
    "    print('paragraph id: {0}, similarity: {1}'.format(\n",
    "        similar['paraid'],\n",
    "        similar['similarity']))\n",
    "    print('paragraph is:')\n",
    "    print(similar['paracontent'])\n",
    "    print('###############################')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 以Keras为例的神经网络模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.1 神经网络的基础：感知机"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "感知机在机器学习中有举足轻重的地位，它是SVM和神经网络的基础。\n",
    "\n",
    "总的来说，感知机是机器学习、数据挖掘、神经网络、深度学习等当前计算机行业热门研究方向的基础。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "感知器的最初概念可以追溯到Warren McCulloch和Walter Pitts在1943年的研究Warren McCulloch和Walter Pitts在1943年的研究，他们将生物神经元类比成带有二值输出的简单逻辑门。\n",
    "\n",
    "以更直观的方式来看，神经元可被理解为生物大脑中神经网络的子节点。\n",
    "\n",
    "在这里，变量信号抵达树突。输入信号在神经细胞体内聚集，当聚集的信号强度超过一定的阈值，就会产生一个输出信号，并被树突传递下去。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/gzj6.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "后来，Frank Rosenblatt 1957年发表了一篇论文《The perceptron, a perceiving and recognizing automaton Project Para》。这篇文章最大的贡献就是基于神经元定义了感知机算法的概念。并说明了，感知机算法的目的，就是针对多维特征的样本集合，学习一个权值向量W，使得W乘以输入特征向量X之后，基于乘积，可以判断一个神经元是否被激活。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据感知器的分类示例："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/gzj.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/gzj2.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从机器学习的角度来讲，感知器属于监督学习（supervised learning），它是一个单层的二分类器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "感知器是如何工作的呢？如图："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/gzj3.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本例中的感知机有三个输入: x1,x2,x3 。通常，它可以有更多或者更少的输入。Rosenblatt提出了一种计算输出的简单的规则。他引入了权重（weight）， w1,w2,… ，等实数来表示各个输入对于输出的重要程度。神经元的输出是0还是1，由加权和 ∑<sub>j</sub>w<sub>j</sub>x<sub>j</sub> 是否小于或者大于某一个阈值（threshold value）。和权重一样，阈值也是一个实数，同时它是神经元的一个参数。使用更严密的代数形式来表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/gzj5.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这就是感知机的工作方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 广义线性模型下的感知机"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "感知机模型是一个二分类模型，和线性回归模型一样，感知机模型一般会使用一些特征函数φ(x)，将输入空间映射到新的特征空间中，再进行计算。\n",
    "\n",
    "感知机模型对应于特征空间中将实例划分为正负两类的分离超平面，故而是判别式模型。感知机模型的数学表达式如下:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/gzj8.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其工作模型如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/gzj9.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此，神经网络的输出层，隐藏层，连接层以及输出层就有雏形了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里f(.)叫做激活函数(Activation function)，也可以理解为f(x) = sign(w*x+b)。\n",
    "\n",
    "在神经网络中，激活函数，是非线性函数，例如："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/gzj10.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以理解为+1为正例，-1为负例，即激活函数达到输出结果的目的，即二分类。也有正例是1，负例是0的做法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个激活函数，也被称为单位阶跃函数:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/gzj11.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 感知机的缺点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "感知机是线性的模型，其不能表达复杂的函数，不能出来线性不可分的问题，其连异或问题(XOR）都无法解决，因为异或问题是线性不可分的，怎样解决这个问题呢，通常有两种做法。 \n",
    "\n",
    "其一：用更多的感知机去进行学习，这也就是人工神经网络的由来。 \n",
    "\n",
    "其二：用非线性模型，核技巧，如SVM进行处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "附注：通过与门，与非门，或门，实现异或门的图示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/gzj12.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/gzjxor.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "或者更直观通过下图表示，通过多个感知机解决线性不可分问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/gzj13.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.2 神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "典型的神经网络图示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/netro1.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现一个神经网络有很多小的感知机组成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/netro2.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z为一个简单的线性分类器，g(z)为对其加上激活函数(Active function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 神经网络激活函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "激活函数是为了解决神经网络线性不可分的问题，神经网络用于实现复杂的函数，非线性激活函数可以使神经网络随意逼近复杂函数。\n",
    "\n",
    "没有激活函数带来的非线性，多层神经网络和单层无异。\n",
    "\n",
    "其特性如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>非线性</b>： 当激活函数是线性的时候，一个两层的神经网络就可以逼近基本上所有的函数了。但是，如果激活函数是恒等激活函数的时候（即f(x)=xf(x)=x），就不满足这个性质了，而且如果MLP使用的是恒等激活函数，那么其实整个网络跟单层神经网络是等价的。\n",
    "\n",
    "- <b>可微性</b>： 当优化方法是基于梯度的时候，这个性质是必须的。\n",
    "- <b>单调性</b>： 当激活函数是单调的时候，单层网络能够保证是凸函数。\n",
    "- <b>f(x)≈x</b>： 当激活函数满足这个性质的时候，如果参数的初始化是random的很小的值，那么神经网络的训练将会很高效；如果不满足这个性质，那么就需要很用心的去设置初始值。\n",
    "- <b>输出值的范围</b>： 当激活函数输出值是 有限 的时候，基于梯度的优化方法会更加 稳定，因为特征的表示受有限权值的影响更显著；当激活函数的输出是 无限 的时候，模型的训练会更加高效，不过在这种情况小，一般需要更小的learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "激活函数也叫传递函数，有许多种类如下图所示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/netro3.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上图从左至右，从上到下分别为sigmoid,tanh,relu,leaky，其中在人工神经网络中常用的是sigmoid函数，卷积神经网络中常用的是relu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid: <img src='./image/sigmoid.svg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanh(双曲正切)：<img src='./image/tanh.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relu(线性整流函数):又称修正线性单元, 是一种人工神经网络中常用的激活函数（activation function），通常指代以斜坡函数及其变种为代表的非线性函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其数学公式为：f(x)=max(0,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leaky Relu: 其数学公式为：\n",
    "\n",
    "f(x)=max(0.1x, x) \n",
    "\n",
    "Leaky ReLU 的概念是：当 x < 0 时，它得到 0.1 的正梯度。\n",
    "\n",
    "该函数一定程度上缓解了 dead ReLU 问题，但是使用该函数的结果并不连贯。\n",
    "\n",
    "尽管它具备 ReLU 激活函数的所有特征，如计算高效、快速收敛、在正区域内不会饱和。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为什么需要激活函数？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单来说有两个原因：\n",
    "\n",
    "> - 是否允许当前的信号传递过去，或者以多大的信号传递过去\n",
    "- 使其变成非线性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们不能将所有的信号都传递到下一层，因此要有选择的进行传递，即激励函数可以做到这一点。\n",
    "\n",
    "同时如果不加激励函数，直接让信号过去，那么相当于线性分类器，并没有改变分类器的本质。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 神经网络过拟合问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络的表达能力是非常强大的，只有给予足够多的神经元，通常其都面临着过拟合的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">名词解释\n",
    "<br><b>过拟合(over-fitting)</b>: <br>所谓过拟合（over-fitting）其实就是所建的机器学习模型或者是深度学习模型在训练样本中表现得过于优越，导致在验证数据集以及测试数据集中表现不佳。\n",
    "<br>打个比喻就是当我需要建立好一个模型之后，比如是识别一只狗狗的模型，我需要对这个模型进行训练。\n",
    "<br>恰好，我训练样本中的所有训练图片都是二哈，那么经过多次迭代训练之后，模型训练好了，并且在训练集中表现得很好。基本上二哈身上的所有特点都涵括进去，那么问题来了！\n",
    "<br>假如我的测试样本是一只金毛呢？将一只金毛的测试样本放进这个识别狗狗的模型中，很有可能模型最后输出的结果就是金毛不是一条狗（因为这个模型基本上是按照二哈的特征去打造的）。\n",
    "<br>所以这样就造成了模型过拟合，虽然在训练集上表现得很好，但是在测试集中表现得恰好相反，在性能的角度上讲就是协方差过大（variance is large），同样在测试集上的损失函数（cost function）会表现得很大。\n",
    "<br>\n",
    "<br><b>欠拟合(under-fitting): </b>\n",
    "<br>相对过拟合欠拟合还是比较容易理解。\n",
    "<br>还是拿刚才的模型来说，可能二哈被提取的特征比较少，导致训练出来的模型不能很好地匹配，表现得很差，甚至二哈都无法识别。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">过拟合与欠拟合的图例："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/fittingresult.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/netro4.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，过多的隐含层和神经元的节点，会带来过拟合的问题。\n",
    "\n",
    "对于神经网络，参数膨胀原因可能是因为随着网路深度的增加，同时参数也不断增加，并且增加速度、规模都很大。那么可以<b>采取减少神经网络规模（深度）的方法</b>。\n",
    "\n",
    "同常来说<font color='red'><b>不应该通过降低神经网络的参数量来减少过拟合</b></font>，可以用正则化项对其进行惩罚或者时通过<font color='red'>dropout</font>进行一部分神经元的随机失活。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/dropout.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其实最关键的是：<font color='red'><b>增大训练样本规模</b></font>防止过拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "增大训练样本其实是很难的工作，一般来说，我们会先将机器学习/ 神经网络相关的代码先写好。\n",
    "\n",
    "然后将一定范围的文档，根据关键字跑出疑似正例的语句集合，并请Analyst对这些语句做出类别判定并标记tag，作为最初的样本。\n",
    "\n",
    "这个最初样本即可作为训练集建模，先让模型框架跑起来，之后根据测试集的情况，补充或修订训练集。\n",
    "\n",
    "大致的流程如下图："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/modelcircle.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 神经网络欠拟合问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "欠拟合基本上都会发生在训练刚开始的时候，经过不断训练之后欠拟合应该不怎么考虑了。\n",
    "\n",
    "但是如果真的还是存在的话，可以通过增加网络复杂度或者在模型中增加多点特征点，这些都是很好解决欠拟合的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 神经网络反向传播算法(Back Propagation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络的训练算法：反向传播算法(Back Propagation)分二步进行，即正向传播和反向传播。这两个过程简述如下：\n",
    "\n",
    "1．正向传播\n",
    "\n",
    "输入的样本从输入层经过隐单元一层一层进行处理，传向输出层；在逐层处理的过程中。在输出层把当前输出和期望输出进行比较，如果现行输出不等于期望输出，则进入反向传播过程。\n",
    "\n",
    "2．反向传播\n",
    "\n",
    "反向传播时，把误差信号按原来正向传播的通路反向传回，逐层修改连接权值，以望代价函数趋向最小。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "反向传播算法的核心目的是对于神经网络中的任何weight或bias计算：损失函数C关于它们的偏导数∂C/∂w. 这个式子能够帮助我们知道当我们改变w或b的时候，损失函数C是怎么变化的。\n",
    "\n",
    "虽然计算这个式子可能有一点复杂，但是它提供了一种自然的，直观的解释，所以说反向传播算法并不仅仅是一种快速学习算法，它提供给我们具体的见解，帮助我们理解改变神经网络的参数是如何改变神经网络行为的。所以说反向传播算法是很值得我们去深入学习的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">名词解释\n",
    "- 损失函数、代价函数与目标函数\n",
    "<br>不严格的说，损失函数和代价函数是同一个东西，目标函数是一个与他们相关但更广的概念，对于目标函数来说在有约束条件下的最小化就是损失函数（loss function）\n",
    "<br>把最大化或者最小化的函数称为目标函数\n",
    "<br>把需要最小化的函数称为代价函数或者损失函数，因为我们的优化是最小化代价或者损失。\n",
    "<br>也就是代价函数与损失函数也属于目标函数，有些目标是最大化，那么就不能叫做损失函数或者代价函数了。\n",
    "<br>更直观的定义:\n",
    "<br>Loss Function 是定义在单个样本上的，算的是一个样本的误差。\n",
    "<br>Cost Function 是定义在整个训练集上的，是所有样本误差的平均，也就是损失函数的平均。\n",
    "<br>Object Function（目标函数 ）定义为：Cost Function + 正则化项。\n",
    "<br>如图：\n",
    "<br><img src='./image/mlfunction.png' />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">目标函数，损失函数，代价函数的探讨\n",
    "<br><img src='./image/mlfunction2.png' />\n",
    "<br><img src='./image/mlfunction3.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 反向传播的直观描述\n",
    "\n",
    "有这么一个神经网络:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/netro5.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设每个训练样本为(向量x, 向量t)，其中向量x是训练样本的特征，而向量t是样本的目标值\n",
    "\n",
    "首先，我们根据样本的特征向量x，计算出神经网络中每个隐藏层节点的输出a<sub>i</sub>，以及输出层每个节点的输出y<sub>i</sub>。\n",
    "\n",
    "然后，我们按照下面的方法计算出每个节点的误差项δ<sub>i</sub>：\n",
    "- 对于输出层节点i:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/netrof1.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中δ<sub>i</sub>是节点i的误差项，y<sub>i</sub>是节点i的输出值，t<sub>i</sub>是样本对应于节点i的目标值。\n",
    "\n",
    "举个例子，根据上图，对于输出层节点8来说，它的输出值为y<sub>1</sub>，而样本的目标值是t<sub>1</sub>，代入上面的公式得到节点8的误差项应该是δ<sub>8</sub>:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/netrof2.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 对于隐藏层节点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/netrof3.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中，a<sub>i</sub>是节点i的输出值，w<sub>ki</sub>是节点i到它的下一层节点k的连接的权重，δ<sub>k</sub>是节点i的下一层节点k的误差项。例如，对于隐藏层节点4来说，计算方法如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/netrof4.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，更新每个连接上的权值："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/netrof5.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中，w<sub>ji</sub>是节点i到节点j的权重，η(eta)是一个成为学习速率的常数，δ<sub>j</sub>是节点j的误差项，x<sub>ji</sub>是节点i传递给节点j的输入。例如，权重w<sub>84</sub>的更新方法如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/netrof6.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "类似的，权值w<sub>41</sub>的更新方法如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/netrof7.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "偏置项的输入值永远为1。例如，节点w<sub>4b</sub>的偏置项应该按照下面的方法计算："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/netrof8.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们已经介绍了神经网络每个节点误差项的计算和权重更新方法。\n",
    "\n",
    "显然，计算一个节点的误差项，需要先计算每个与其相连的下一层节点的误差项。\n",
    "\n",
    "这就要求误差项的计算顺序必须是从输出层开始，然后反向依次计算每个隐藏层的误差项，直到与输入层相连的那个隐藏层。\n",
    "\n",
    "这就是反向传播算法的名字的含义。当所有节点的误差项计算完毕后，我们就可以根据式5来更新所有的权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上就是基本的反向传播算法，并不是很复杂，您弄清楚了么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 反向传播算法的推导"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "反向传播算法其实就是链式求导法则的应用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：下面的数学公式部分，看看即可，如果感兴趣可以去：[零基础入门深度学习(3) - 神经网络和反向传播算法](https://www.zybuluo.com/hanbingtao/note/476663#an1)深入学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先我们看4个方程式："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/netrof9.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BP1：方程一：输出层的error(计算最后一层神经网络产生的错误) δ<sup>L</sup>\n",
    "- BP2: 方程二：用当前层error表示下一层error(由后往前，计算每一层神经网络产生的错误)\n",
    "- BP3: 方程三：error等价于损失函数C对bias的变化率(计算权重的梯度)\n",
    "- BP4: 方程四：损失函数C对weights的变化率(计算偏置的梯度)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "附注：Hadamard积,数学表示为：s⊙t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">反向传播要基于常见的线性代数运算，像矩阵的加、乘等等。但是有一种运算是不常见的。例如，s和t是两个相同维度的向量，我们使用s⊙t表示两个向量按元素的积（elementwise product），因此 s⊙t 的元素 (s⊙t)<sub>j</sub>=s<sub>j</sub>t<sub>j</sub> 。如："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/vectorpointmul.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这四个方程的证明主要用到<font color='red'>多元函数微分的链式法则</font>，举例证明公式BP1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/netrof10.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BP2, BP3, BP4可以根据上面的参考文章学习，或自行推导, 推导过程参见：[反向传播算法（过程及公式推导）](https://blog.csdn.net/u014313009/article/details/51039334)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 反向传播算法梯度计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/netrof11.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从算法的流程也可以明白为什么它被称为反向传播算法，因为我们是从最后一层的δ<sup>L</sup>开始反向计算前面的δ<sup>l</sup>的。\n",
    "\n",
    "因为损失函数是关于神经网络输出的函数，所以为了得到损失函数关于前面层的参数的梯度就需要不断的应用求导链式法则，一层层向前推导得到我们需要的关系的表达式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 反向传播为什么被认为是快速的算法？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "反向传播算法的聪明之处在于我们只需要一次正向遍历神经网络和一次反向遍历神经网络，就可以计算出所有的梯度∂C/∂w<sub>j</sub>\n",
    "\n",
    "正向遍历计算a<sup>l</sup><sub>j</sub>和z<sup>l</sup><sub>j</sub>，反向遍历计算各个δ<sup>l</sup><sub>j</sub>，然后经过简单计算就得到了需要的梯度值。\n",
    "\n",
    "所以说虽然从形式上可能会觉得反向传播算法更复杂，但其实它的计算量更少，算法更高效。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 反向传播算法的应用意义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络的训练规则是根据激活函数是sigmoid函数、平方和误差、全连接网络、随机梯度下降优化算法。\n",
    "\n",
    "如果激活函数不同、误差计算方式不同、网络连接结构不同、优化算法不同，则具体的训练规则也会不一样。\n",
    "\n",
    "但是无论怎样，训练规则的推导方式都是一样的，应用链式求导法则进行推导即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 揭开神经网络的盖头"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过了这么多准备工作，我们看看神经网络究竟是什么。\n",
    "\n",
    "先看看多层感知机，顾名思义，就是有多个隐含层的感知机，我们看一下多层感知机的结构："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/mp.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多层感知机可以摆脱早期离散传输函数的束缚。\n",
    "\n",
    "使用sigmoid或tanh等连续函数模拟神经元对激励的响应。\n",
    "\n",
    "在训练算法上则使用Werbos发明的反向传播BP算法。\n",
    "\n",
    "这货:多层感知机就是我们现在所说的神经网络NN——神经网络听起来不知道比感知机高端到哪里去了！\n",
    "\n",
    "多层感知机解决了之前无法模拟异或逻辑的缺陷，同时更多的层数也让网络更能够刻画现实世界中的复杂情形。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 神经网络开始阶段的困境"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随着神经网络层数的加深，优化函数越来越容易陷入局部最优解，并且这个“陷阱”越来越偏离真正的全局最优。\n",
    "\n",
    "利用有限数据训练的深层网络，性能还不如较浅层网络。\n",
    "\n",
    "同时，另一个不可忽略的问题是随着网络层数增加，“梯度消失”现象更加严重。\n",
    "\n",
    "具体来说，我们常常使用sigmoid作为神经元的输入输出函数。\n",
    "\n",
    "对于幅度为1的信号，在BP反向传播梯度时，每传递一层，梯度衰减为原来的0.25。\n",
    "\n",
    "层数一多，梯度指数衰减后低层基本上接受不到有效的训练信号。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 解决困境的思路"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### a. 预训练\n",
    "2006年，Hinton利用预训练方法缓解了局部最优解问题，将隐含层推动到了7层，神经网络真正意义上有了“深度”，由此揭开了深度学习的热潮。\n",
    "\n",
    "这里的“深度”并没有固定的定义——在语音识别中4层网络就能够被认为是“较深的”，而在图像识别中20层以上的网络屡见不鲜。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### b. 改变激活函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了克服梯度消失，ReLU、maxout等传输函数代替了 sigmoid，形成了如今 DNN 的基本形式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DNN的新困境"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/dnn.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如图所示，我们看到全连接DNN的结构里下层神经元和所有上层神经元都能够形成连接，带来的潜在问题是参数数量的膨胀。\n",
    "\n",
    "假设输入的是一幅像素为1K*1K的图像，隐含层有1M个节点，光这一层就有10^12个权重需要训练，这不仅容易过拟合，而且极容易陷入局部最优。\n",
    "\n",
    "此时我们可以引出卷积神经网络CNN的课题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.3 卷积神经网络(CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积神经网络（Convolutional Neural Networks, CNN）是一类包含卷积或相关计算且具有深度结构的前馈神经网络（Feedforward Neural Networks），是深度学习（deep learning）的代表算法之一  。由于卷积神经网络能够进行平移不变分类（shift-invariant classification），因此也被称为“平移不变人工神经网络（Shift-Invariant Artificial Neural Networks, SIANN）”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了解决当神经网络的深度、节点数变大，会导致过拟合、参数过多等问题，加入如下思考："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 通过抽取只依赖图像里小的子区域的局部特征，然后利用这些特征的信息就可以融合到后续处理阶段中，从而检测更高级的特征，最后产生图像整体的信息。\n",
    "- 距离较近的像素的相关性要远大于距离较远像素的相关性。\n",
    "- 对于图像的一个区域有用的局部特征可能对于图像的其他区域也有用，例如感兴趣的物体发生平移的情形。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.3.1 特性：局部连接(Sparse Connectivity)与权值共享(Shared Weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下图是一个很经典的图示，左边是全连接，右边是局部连接。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/cnnlocal.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于一个1000 × 1000的输入图像而言，如果下一个隐藏层的神经元数目为10^6个，采用全连接则有1000 × 1000 × 10^6 = 10^12个权值参数，如此数目巨大的参数几乎难以训练；\n",
    "\n",
    "而采用<b>局部连接</b>，隐藏层的每个神经元仅与图像中10 × 10的局部图像相连接，那么此时的权值参数数量为10 × 10 × 10^6 = 10^8，将直接减少4个数量级。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尽管减少了几个数量级，但参数数量依然较多。能不能再进一步减少呢？能！方法就是<b>权值共享</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/cnnsw.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "具体做法是，在局部连接中隐藏层的每一个神经元连接的是一个10 × 10的局部图像，因此有10 × 10个权值参数，将这10 × 10个权值参数共享给剩下的神经元，也就是说隐藏层中10^6个神经元的权值参数相同，那么此时不管隐藏层神经元的数目是多少，需要训练的参数就是这 10 × 10个权值参数（也就是卷积核(也称滤波器)的大小）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这大概就是CNN的一个神奇之处，尽管只有这么少的参数，依旧有出色的性能。\n",
    "\n",
    "但是，这样仅提取了图像的一种特征，如果要多提取出一些特征，可以增加多个卷积核，不同的卷积核能够得到图像的不同映射下的特征，称之为Feature Map。\n",
    "\n",
    "如果有100个卷积核，最终的权值参数也仅为100 × 100 = 10^4个而已。另外，偏置参数也是共享的，同一种滤波器共享一个。\n",
    "\n",
    "卷积神经网络的核心思想是：局部感受野(local field)，权值共享以及时间或空间亚采样这三种思想结合起来，获得了某种程度的位移、尺度、形变不变性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.3.2 网络结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下图是一个经典的CNN结构，称为LeNet-5网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/lenet5.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，CNN中主要有两种类型的网络层，分别是卷积层和池化/采样层(Pooling)。\n",
    "\n",
    "卷积层的作用是提取图像的各种特征；\n",
    "\n",
    "池化层的作用是对原始特征信号进行抽象，从而大幅度减少训练参数，另外还可以减轻模型过拟合的程度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.3.3 前向传播"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.4.3.3.1 卷积层(Convolutional Layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全连接层的方式对于图像数据来说似乎显得不这么友好，因为图像本身具有“二维空间特征”，通俗点说就是局部特性。\n",
    "\n",
    "譬如我们看一张猫的图片，可能看到猫的眼镜或者嘴巴就知道这是张猫片，而不需要说每个部分都看完了才知道，啊，原来这个是猫啊。\n",
    "\n",
    "所以如果我们可以用某种方式对一张图片的某个典型特征识别，那么这张图片的类别也就知道了。这个时候就产生了卷积的概念。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积层是卷积核在上一级输入层上通过逐一滑动窗口计算而得，卷积核中的每一个参数都相当于传统神经网络中的权值参数，与对应的局部像素相连接，将卷积核的各个参数与对应的局部像素值相乘之和，（通常还要再加上一个偏置参数），得到卷积层上的结果。如下图所示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/cnncl.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的动图能够更好地解释卷积过程："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/convolved.gif' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再详细一些，举一个例子，现在有一个4*4的图像，我们设计两个卷积核，看看运用卷积核后图片会变成什么样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/cnnclcal.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由上图可以看到，原始图片是一张灰度图片,每个位置表示的是像素值，0表示白色，1表示黑色，（0，1）区间的数值表示灰色。对于这个4*4的图像，我们采用两个2*2的卷积核来计算。\n",
    "\n",
    "设定步长为1，即每次以2*2的固定窗口往右滑动一个单位。以第一个卷积核filter1为例，计算过程如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "feature_map1(1,1) = 1*1 + 0*(-1) + 1*1 + 1*(-1) = 1 \n",
    "feature_map1(1,2) = 0*1 + 1*(-1) + 1*1 + 1*(-1) = -1 \n",
    "feature_map1(3,3) = 1*1 + 0*(-1) + 1*1 + 0*(-1) = 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到这就是最简单的内积公式。feature_map1(1,1)表示在通过第一个卷积核计算完后得到的feature_map的第一行第一列的值，随着卷积核的窗口不断的滑动，我们可以计算出一个3*3的feature_map1;同理可以计算通过第二个卷积核进行卷积运算后的feature_map2，那么这一层卷积操作就完成了。\n",
    "\n",
    "feature_map尺寸计算公式：[ (原图片尺寸 -卷积核尺寸)/ 步长 ] + 1。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到，同一层的神经元可以共享卷积核，那么对于高位数据的处理将会变得非常简单。\n",
    "\n",
    "并且使用卷积核后图片的尺寸变小，方便后续计算，并且我们不需要手动去选取特征，只用设计好卷积核的尺寸，数量和滑动的步长就可以让它自己去训练了，省时又省力啊。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 为什么卷积核有效？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为什么使用卷积核计算后分类效果要由于普通的神经网络呢？\n",
    "\n",
    "我们仔细来看一下上面计算的结果：\n",
    "\n",
    "通过第一个卷积核计算后的feature_map是一个三维数据，在第三列的绝对值最大，说明原始图片上对应的地方有一条<b>垂直方向的特征</b>，即像素数值变化较大；\n",
    "\n",
    "而通过第二个卷积核计算后，第三列的数值为0，第二行的数值绝对值最大，说明原始图片上对应的地方有一条<b>水平方向的特征</b>。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "仔细思考一下，这个时候，我们设计的两个卷积核分别能够提取，或者说检测出原始图片的特定的特征。\n",
    "\n",
    "此时我们其实就可以把卷积核就理解为特征提取器啊！\n",
    "\n",
    "现在就明白了，为什么我们只需要把图片数据灌进去，设计好卷积核的尺寸、数量和滑动的步长就可以让自动提取出图片的某些特征，从而达到分类的效果啊！\n",
    "\n",
    "注：\n",
    "\n",
    "1.此处的卷积运算是两个卷积核大小的矩阵的内积运算，不是矩阵乘法。即相同位置的数字相乘再相加求和。不要弄混淆了。\n",
    "\n",
    "2.卷积核的公式有很多，这只是最简单的一种。我们所说的卷积核在数字信号处理里也叫滤波器，那滤波器的种类就多了，均值滤波器，高斯滤波器，拉普拉斯滤波器等等，不过，不管是什么滤波器，都只是一种数学运算，无非就是计算更复杂一点。\n",
    "\n",
    "3.每一层的卷积核大小和个数可以自己定义，不过一般情况下，根据实验得到的经验来看，会在越靠近输入层的卷积层设定少量的卷积核，越往后，卷积层设定的卷积核数目就越多"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.4.3.3.2 下采样(池化)层(Pooling Layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过卷积层获得了图像的特征之后，理论上我们可以直接使用这些特征训练分类器（如softmax），但是这样做将面临巨大的计算量的挑战，而且容易产生过拟合的现象。\n",
    "\n",
    "为了进一步降低网络训练参数及模型的过拟合程度，我们对卷积层进行池化/采样(Pooling)处理。\n",
    "\n",
    "池化规模一般为2x2\n",
    "\n",
    "池化层的主要目的是通过降采样的方式，在不影响图像质量的情况下，压缩图片，减少参数。\n",
    "\n",
    "池化/采样的方式通常有以下几种：\n",
    "\n",
    "- Max-Pooling: 选择Pooling窗口中的最大值作为采样值；\n",
    "- Mean-ooling: 将Pooling窗口中的所有值相加取平均，以平均值作为采样值；\n",
    "- 高斯池化。借鉴高斯模糊的方法\n",
    "- 可训练池化。训练函数 ff ，接受4个点为输入，输出1个点\n",
    "\n",
    "如下图所示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/cnnpool.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算示例: <img src='./image/cnnpool2.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单来说，假设现在设定池化层采用MaxPooling，大小为2*2，步长为1，取每个窗口最大的数值重新，那么图片的尺寸就会由3*3变为2*2：(3-2)+1=2。从上例来看，会有如下变换："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算示例: <img src='./image/cnnpool3.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 为什么采用Max Pooling？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从计算方式来看，算是最简单的一种了，取max即可，但是这也引发一个思考，为什么需要Max Pooling，意义在哪里？\n",
    "\n",
    "如果我们只取最大值，那其他的值被舍弃难道就没有影响吗？不会损失这部分信息吗？\n",
    "\n",
    "如果认为这些信息是可损失的，那么是否意味着我们在进行卷积操作后仍然产生了一些不必要的冗余信息呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其实从上文分析卷积核为什么有效的原因来看，每一个卷积核可以看做一个特征提取器，不同的卷积核负责提取不同的特征，我们例子中设计的第一个卷积核能够提取出“垂直”方向的特征，第二个卷积核能够提取出“水平”方向的特征，那么我们对其进行<b>Max Pooling操作后，提取出的是真正能够识别特征的数值</b>，其余被舍弃的数值，对于我提取特定的特征并没有特别大的帮助。\n",
    "\n",
    "那么在进行后续计算使，减小了feature map的尺寸，从而减少参数，达到减小计算量，且不损失效果的情况。\n",
    "\n",
    "不过并不是所有情况Max Pooling的效果都很好，有时候有些周边信息也会对某个特定特征的识别产生一定效果，那么这个时候舍弃这部分“不重要”的信息，就不划算了。\n",
    "\n",
    "所以具体情况得具体分析，如果加了Max Pooling后效果反而变差了，不如把卷积后不加Max Pooling的结果与卷积后加了Max Pooling的结果输出对比一下，看看Max Pooling是否对卷积核提取特征起了反效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.4.3.3.3 Flattern层与全连接层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到这一步，其实我们的一个完整的前向传播的“卷积部分”就算完成了，如果想要叠加层数，一般也是叠加“Conv-MaxPooing\",通过不断的设计卷积核的尺寸，数量，提取更多的特征，最后识别不同类别的物体。\n",
    "\n",
    "做完Max Pooling后，我们就会把这些数据“拍平”，丢到Flatten层，然后把Flatten层的output放到full connected Layer里，采用softmax对其进行分类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/cnnfc.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.3.4 后向传播"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.4.3.4.1 卷积层(Convolutional Layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当一个卷积层L的下一层(L+1)为采样层，并假设我们已经计算得到了采样层的残差，现在计算该卷积层的残差。\n",
    "\n",
    "从LeNet-5网络结构图我们知道，采样层（L+1）的map大小是卷积层L的1/（scale*scale），以scale=2为例，但这两层的map个数是一样的，卷积层L的某个map中的4个单元与L+1层对应map的一个单元关联，可以对采样层的残差与一个scale*scale的全1矩阵进行[克罗内克积](https://baike.baidu.com/item/%E5%85%8B%E7%BD%97%E5%86%85%E5%85%8B%E7%A7%AF/6282573?fr=aladdin) 进行扩充，使得采样层的残差的维度与上一层的输出map的维度一致。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "克罗内克积示例：<img src='./image/hadamard.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "扩展过程："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/cnnbcl.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用卷积计算卷积层的残差："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/cnnbcl2.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.4.3.4.2 下采样(池化)层(Pooling Layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当某个采样层L的下一层是卷积层(L+1)，并假设我们已经计算出L+1层的残差，现在计算L层的残差。\n",
    "\n",
    "采样层到卷积层直接的连接是有权重和偏置参数的，因此不像卷积层到采样层那样简单。\n",
    "\n",
    "现再假设L层第j个map Mj与L+1层的M2j关联，按照BP的原理，L层的残差Dj是L+1层残差D2j的加权和，但是这里的困难在于，我们很难理清M2j的那些单元通过哪些权重与Mj的哪些单元关联，这里需要两个小的变换（rot180°和padding）："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rot180°：旋转：表示对矩阵进行180度旋转（可通过行对称交换和列对称交换完成）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def fz(a):\n",
    "    return a[::-1]\n",
    "\n",
    "def rot180(mat):\n",
    "    return np.array(fz(list(map(fz, mat))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]]\n",
      "[[15 14 13 12]\n",
      " [11 10  9  8]\n",
      " [ 7  6  5  4]\n",
      " [ 3  2  1  0]]\n"
     ]
    }
   ],
   "source": [
    "A = np.arange(16).reshape((4,4))\n",
    "B = rot180(A)\n",
    "print(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero padding:扩充"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的图片由4\\*4，通过卷积层变为3\\*3，再通过池化层变化2\\*2，如果我们再添加层，那么图片岂不是会越变越小？\n",
    "\n",
    "这个时候我们就会引出“Zero Padding”（补零），它可以帮助我们保证每次经过卷积或池化输出后图片的大小不变，如，上述例子我们如果加入Zero Padding，再采用3\\*3的卷积核，那么变换后的图片尺寸与原图片尺寸相同，如下图所示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/cnnpadding.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常情况下，我们希望图片做完卷积操作后保持图片大小不变，所以我们一般会选择尺寸为3\\*3的卷积核和1的zero padding，或者5\\*5的卷积核与2的zero padding。\n",
    "\n",
    "这样通过计算后，可以保留图片的原始尺寸。\n",
    "\n",
    "那么加入zero padding后的feature_map尺寸 =( width + 2 * padding_size - filter_size )/stride + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比如: 如果原矩阵为4x4，则width为3， 如果需要加1个padding size，卷积核为3x3，则filter_size为3，stride为1，则：\n",
    "\n",
    "feature_map size = (4+ 2*1 - 3)/1 + 1 = 4, 即feature_map为4x4的方阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding的实现代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(in_data, size):\n",
    "    cur_r, cur_w = in_data.shape[0], in_data.shape[1]\n",
    "    new_r = cur_r + size * 2\n",
    "    new_w = cur_w + size * 2\n",
    "    ret = np.zeros((new_r, new_w))\n",
    "    ret[size:cur_r + size, size:cur_w+size] = in_data\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "in_data = np.ones((4,4))\n",
    "print(in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 1. 0.]\n",
      " [0. 1. 1. 1. 1. 0.]\n",
      " [0. 1. 1. 1. 1. 0.]\n",
      " [0. 1. 1. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(padding(in_data, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "旋转180度与padding的综合图例，如："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/cnnrp.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.3.4 LeNet-5网络详解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上较详细地介绍了CNN的网络结构和基本原理，下面介绍一个经典的CNN模型：LeNet-5网络。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet-5：是Yann LeCun在1998年设计的用于手写数字识别的卷积神经网络，当年美国大多数银行就是用它来识别支票上面的手写数字的，它是早期卷积神经网络中最有代表性的实验系统之一。\n",
    "\n",
    "LenNet-5共有7层（不包括输入层），每层都包含不同数量的训练参数，其中主要有2个卷积层，2个下抽样层（池化层），3个全连接层3种连接方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. C1卷积层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/lenet51.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. S2池化层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/lenet52.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. C3卷积层\n",
    "\n",
    "输入：S2中所有6个或者几个特征map组合\n",
    "\n",
    "卷积核大小：5\\*5\n",
    "\n",
    "卷积核种类：16\n",
    "\n",
    "输出featureMap大小：10\\*10 (14-5+1)=10\n",
    "\n",
    "C3中的每个特征map是连接到S2中的所有6个或者几个特征map的，表示本层的特征map是上一层提取到的特征map的不同组合\n",
    "\n",
    "存在的一个方式是：C3的前6个特征图以S2中3个相邻的特征图子集为输入。接下来6个特征图以S2中4个相邻特征图子集为输入。然后的3个以不相邻的4个特征图子集为输入。最后一个将S2中所有特征图为输入。\n",
    "\n",
    "则：可训练参数：6\\*(3\\*5\\*5+1)+6\\*(4\\*5\\*5+1)+3\\*(4\\*5\\*5+1)+1\\*(6\\*5\\*5+1)=1516\n",
    "\n",
    "连接数：10\\*10\\*1516=151600\n",
    "\n",
    "详细说明：第一次池化之后是第二次卷积，第二次卷积的输出是C3，16个10x10的特征图，卷积核大小是 5\\*5. 我们知道S2 有6个 14\\*14 的特征图，怎么从6 个特征图得到 16个特征图了？ 这里是通过对S2 的特征图特殊组合计算得到的16个特征图。具体如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/lenet53_1.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">```\n",
    "C3的前6个feature map（对应上图第一个红框的6列）与S2层相连的3个feature map相连接（上图第一个红框），后面6个feature map与S2层相连的4个feature map相连接（上图第二个红框），后面3个feature map与S2层部分不相连的4个feature map相连接，最后一个与S2层的所有feature map相连。卷积核大小依然为5*5，所以总共有6*(3*5*5+1)+6*(4*5*5+1)+3*(4*5*5+1)+1*(6*5*5+1)=1516个参数。而图像大小为10*10，所以共有151600个连接。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/lenet53.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/lenet53_2.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. S4池化层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "输入：10*10\n",
    "\n",
    "采样区域：2*2\n",
    "\n",
    "采样方式：4个输入相加，乘以一个可训练参数，再加上一个可训练偏置。结果通过sigmoid\n",
    "\n",
    "采样种类：16\n",
    "\n",
    "输出featureMap大小：5*5（10/2）\n",
    "\n",
    "神经元数量：5*5*16=400\n",
    "\n",
    "连接数：16*（2*2+1）*5*5=2000\n",
    "\n",
    "S4中每个特征图的大小是C3中特征图大小的1/4\n",
    "\n",
    "详细说明：S4是pooling层，窗口大小仍然是2*2，共计16个feature map，C3层的16个10x10的图分别进行以2x2为单位的池化得到16个5x5的特征图。有5x5x5x16=2000个连接。连接的方式与S2层类似。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/lenet54.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. C5卷积层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "输入：S4层的全部16个单元特征map（与s4全相连）\n",
    "\n",
    "卷积核大小：5*5\n",
    "\n",
    "卷积核种类：120\n",
    "\n",
    "输出featureMap大小：1*1（5-5+1）\n",
    "\n",
    "可训练参数/连接：120*（16*5*5+1）=48120\n",
    "\n",
    "详细说明：C5层是一个卷积层。由于S4层的16个图的大小为5x5，与卷积核的大小相同，所以卷积后形成的图的大小为1x1。这里形成120个卷积结果。每个都与上一层的16个图相连。所以共有(5x5x16+1)x120 = 48120个参数，同样有48120个连接。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/lenet55.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. F6全连接层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "输入：c5 120维向量\n",
    "\n",
    "计算方式：计算输入向量和权重向量之间的点积，再加上一个偏置，结果通过sigmoid函数输出。\n",
    "\n",
    "可训练参数:84*(120+1)=10164\n",
    "\n",
    "详细说明：6层是全连接层。F6层有84个节点，对应于一个7x12的比特图，-1表示白色，1表示黑色，这样每个符号的比特图的黑白色就对应于一个编码。该层的训练参数和连接数是(120 + 1)x84=10164。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASCII编码图如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/lenet56_1.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/lenet56.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. 输出层-全连接层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output层也是全连接层，共有10个节点，分别代表数字0到9，且如果节点i的值为0，则网络识别的结果是数字i。\n",
    "\n",
    "采用的是径向基函数（RBF）的网络连接方式。假设x是上一层的输入，y是RBF的输出，则RBF输出的计算方式是："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/rbf.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上式w_ij 的值由i的比特图编码确定，i从0到9，j取值从0到7\\*12-1。\n",
    "\n",
    "RBF输出的值越接近于0，则越接近于i，即越接近于i的ASCII编码图，表示当前网络输入的识别结果是字符i。\n",
    "\n",
    "该层有84x10=840个参数和连接。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/lenet57.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数字3通过LeNet-5的识别过程："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/lenet57_1.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "理论部分说的非常非常多了，下面看一下如何用Keras做一个mnist，即手写数字的CNN神经网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1671)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the convnet \n",
    "class LeNet:\n",
    "    @staticmethod\n",
    "    def build(input_shape, classes):\n",
    "        model = Sequential()\n",
    "        print(input_shape)\n",
    "        # CONV => RELU => POOL\n",
    "        model.add(Conv2D(20, kernel_size=5, padding=\"same\",\n",
    "                         input_shape=input_shape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        # CONV => RELU => POOL\n",
    "        model.add(Conv2D(50, kernel_size=5, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        # Flatten => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation(\"relu\"))\n",
    " \n",
    "        # a softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network and training\n",
    "NB_EPOCH = 20\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "OPTIMIZER = Adam()\n",
    "VALIDATION_SPLIT=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_ROWS, IMG_COLS = 28, 28 # input image dimensions\n",
    "NB_CLASSES = 10  # number of outputs = number of digits\n",
    "INPUT_SHAPE = (1, IMG_ROWS, IMG_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data: shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "K.set_image_dim_ordering(\"th\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider them as float and normalize\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255 \n",
    "X_test /= 255  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为训练一次mnist太慢了，为了演示，仅仅训练10个样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a 60K x [1 x 28 x 28] shape as input to the CONVNET\n",
    "X_train = X_train[:, np.newaxis, :, :][:10]\n",
    "X_test = X_test[:, np.newaxis, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = np_utils.to_categorical(y_train[:10], NB_CLASSES)\n",
    "y_test = np_utils.to_categorical(y_test, NB_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n",
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 2.3392 - acc: 0.1250 - val_loss: 2.2658 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.0183 - acc: 1.0000 - val_loss: 2.0957 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 1.6658 - acc: 1.0000 - val_loss: 1.8799 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2947 - acc: 1.0000 - val_loss: 1.6680 - val_acc: 0.5000\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.9369 - acc: 1.0000 - val_loss: 1.4541 - val_acc: 0.5000\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.5875 - acc: 1.0000 - val_loss: 1.3479 - val_acc: 0.5000\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.3253 - acc: 1.0000 - val_loss: 1.3526 - val_acc: 0.5000\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1664 - acc: 1.0000 - val_loss: 1.3748 - val_acc: 0.5000\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.0737 - acc: 1.0000 - val_loss: 1.4278 - val_acc: 0.5000\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0291 - acc: 1.0000 - val_loss: 1.5385 - val_acc: 0.5000\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 0.0123 - acc: 1.0000 - val_loss: 1.6896 - val_acc: 0.5000\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 1.8554 - val_acc: 0.5000\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 2.0236 - val_acc: 0.5000\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.1876 - val_acc: 0.5000\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 5.6657e-04 - acc: 1.0000 - val_loss: 2.3458 - val_acc: 0.5000\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 2.6962e-04 - acc: 1.0000 - val_loss: 2.4971 - val_acc: 0.5000\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 1.3463e-04 - acc: 1.0000 - val_loss: 2.6404 - val_acc: 0.5000\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 7.0891e-05 - acc: 1.0000 - val_loss: 2.7761 - val_acc: 0.5000\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 3.9281e-05 - acc: 1.0000 - val_loss: 2.9040 - val_acc: 0.5000\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 2.2859e-05 - acc: 1.0000 - val_loss: 3.0249 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "modelpath = './cnnmodel/mnistcnn.h5'\n",
    "model = None\n",
    "if os.path.exists(modelpath):\n",
    "    try:\n",
    "        K.clear_session()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    model = load_model(modelpath)\n",
    "else:\n",
    "    # initialize the optimizer and model\n",
    "    model = LeNet.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n",
    "                  metrics=[\"accuracy\"])\n",
    "    history = model.fit(X_train, y_train, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    epochs=NB_EPOCH, \n",
    "                    verbose=VERBOSE, \n",
    "                    validation_split=VALIDATION_SPLIT)\n",
    "    model.save(modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - ETA: 13 - ETA: 13 - ETA: 14 - ETA: 14 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 15s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test score: 6.58745648727417\n",
      "Test accuracy: 0.4036\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.4 循环神经网络(RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.4.1 RNN概述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1) BP算法,CNN之后, 为什么还有RNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "细想BP算法,CNN(卷积神经网络)我们会发现, 他们的输出都是只考虑前一个输入的影响而不考虑其它时刻输入的影响, 比如简单的猫,狗,手写数字等单个物体的识别具有较好的效果。\n",
    "\n",
    "但是, 对于一些与时间先后有关的, 比如视频的下一时刻的预测,文档前后文内容的预测等, 这些算法的表现就不尽如人意了.因此, RNN就应运而生了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) 什么是RNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN是一种特殊的神经网络结构, 它是根据\"人的认知是基于过往的经验和记忆\"这一观点提出的。\n",
    "\n",
    "它与DNN,CNN不同的是: 它不仅考虑前一时刻的输入,而且赋予了网络对前面的内容的一种'记忆'功能。\n",
    "\n",
    "RNN之所以称为循环神经网络，即一个序列当前的输出与前面的输出也有关。\n",
    "\n",
    "具体的表现形式为网络会对前面的信息进行记忆并应用于当前输出的计算中，即隐藏层之间的节点不再无连接而是有连接的，并且隐藏层的输入不仅包括输入层的输出还包括上一时刻隐藏层的输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) RNN的主要应用领域有哪些呢?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN的应用领域有很多, 可以说只要考虑时间先后顺序的问题都可以使用RNN来解决.这里主要说一下几个常见的应用领域:\n",
    "\n",
    "   ① <font color='red'>自然语言处理(NLP)</font>: 主要有视频处理, 文本生成, 语言模型, 图像处理\n",
    "\n",
    "   ② 机器翻译, 机器写小说\n",
    "\n",
    "   ③ 语音识别\n",
    "\n",
    "   ④ 图像描述生成\n",
    "\n",
    "   ⑤ 文本相似度计算\n",
    "\n",
    "   ⑥ 音乐推荐、网易考拉商品推荐、Youtube视频推荐等新的应用领域."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.4.2 RNN详细介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.4.4.2.1 RNN模型结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面我们说了RNN具有时间\"记忆\"的功能, 那么它是怎么实现所谓的\"记忆\"的呢?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/rnn_1.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如图1所示, 我们可以看到RNN层级结构较之于CNN来说比较简单, 它主要有输入层,Hidden Layer, 输出层组成。\n",
    "\n",
    "注意：图中没有卷积层与池化层。\n",
    "\n",
    "并且会发现在Hidden Layer 有一个箭头表示数据的循环更新, 这个就是实现时间记忆功能的方法.\n",
    "\n",
    "如果到这里你还是没有搞懂RNN到底是什么意思,那么请继续往下看!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/rnn_2.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如图所示为Hidden Layer的层级展开图。\n",
    "\n",
    "t-1, t, t+1表示时间序列 \n",
    "\n",
    "X表示输入的样本。 \n",
    "\n",
    "S<sub>t</sub>表示样本在时间t处的的记忆。\n",
    "\n",
    "S<sub>t</sub> = f(W\\*S<sub>t-1</sub> +U\\*X<sub>t</sub>)。\n",
    "\n",
    "W表示输入的权重\n",
    "\n",
    "U表示此刻输入的样本的权重\n",
    "\n",
    "V表示输出的样本权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在t =1时刻, 一般初始化输入S<sub>0</sub>=0, 随机初始化W,U,V, 进行下面的公式计算:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/rnn_f1.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中,f和g均为激活函数. 其中f可以是tanh,relu,sigmoid等激活函数，g通常是softmax也可以是其他。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 时间就向前推进，此时的状态s<sub>1</sub>作为时刻1的记忆状态将参与下一个时刻的预测活动，也就是:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/rnn_f2.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以此类推, 可以得到最终的输出值为:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/rnn_f3.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意: \n",
    "\n",
    "1. 这里的W,U,V在每个时刻都是相等的(权重共享).\n",
    "\n",
    "2. 隐藏状态可以理解为:  S=f(现有的输入+过去记忆总结) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.4.4.2.2 RNN反向传播"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面我们介绍了RNN的前向传播的方式, 那么RNN的权重参数W,U,V都是怎么更新的呢?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每一次的输出值O<sub>t</sub>都会产生一个误差值E<sub>t</sub>, 则总的误差可以表示为:<img src='./image/rnn_f4.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "则<b>损失函数</b>可以使用<b>交叉熵损失函数</b>也可以使用<b>平方误差损失函数</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于每一步的输出不仅仅依赖当前步的网络，并且还需要前若干步网络的状态，那么这种BP改版的算法叫做<b>Backpropagation Through Time(BPTT)</b> , 也就是将输出端的误差值反向传递,运用梯度下降法进行更新."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">为什么提到梯度就要求偏导数？\n",
    "毕竟求偏导的物理意义是：表示在某一方向速度随位置变化的快慢（类似加速度）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也就是要求参数的梯度:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/rnn_f5.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先我们求解W的更新方法, 由前面的W的更新可以看出它是每个时刻的偏差的偏导数之和. \n",
    "\n",
    "在这里我们以 t = 3时刻为例, 根据链式求导法则可以得到t = 3时刻的偏导数为:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/rnn_f6.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此时, 根据公式<img src='./image/rnn_f7.png' />， 我们会发现, S3除了和W有关之外, 还和前一时刻S2有关.\n",
    "\n",
    "对于S3直接展开得到下面的式子:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/rnn_f8.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于S2直接展开得到下面的式子:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/rnn_f9.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于S1直接展开得到下面的式子:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/rnn_f10.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 将上述三个式子合并得到:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/rnn_f11.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样就得到了公式:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/rnn_f12.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里要说明的是:<img src='./image/rnn_f13.png' />，<br>表示的是S3对W直接求导, 不考虑S2的影响.(也就是例如y = f(x)*g(x)对x求导一样)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其次是对U的更新方法. 由于参数U求解和W求解类似,这里就不在赘述了,最终得到的具体的公式如下:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/rnn_f14.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后,给出V的更新公式(V只和输出O有关):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/rnn_f15.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.4.3 RNN的一些改进算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面我们介绍了RNN的算法, 它处理时间序列的问题的效果很好, 但是仍然存在着一些问题, 其中较为严重的是容易出现梯度消失或者梯度爆炸的问题(BP算法和长时间依赖造成的). 注意: 这里的梯度消失和BP的不一样,这里主要指由于时间过长而造成记忆值较小的现象.\n",
    "\n",
    "因此, 就出现了一系列的改进的算法, 这里介绍主要的两种算法: LSTM 和 GRU.\n",
    "\n",
    "LSTM 和 GRU对于梯度消失或者梯度爆炸的问题处理方法主要是:\n",
    "\n",
    "对于梯度消失: 由于它们都有特殊的方式存储”记忆”，那么以前梯度比较大的”记忆”不会像简单的RNN一样马上被抹除，因此可以一定程度上克服梯度消失问题。\n",
    "\n",
    "对于梯度爆炸:用来克服梯度爆炸的问题就是gradient clipping，也就是当你计算的梯度超过阈值c或者小于阈值-c的时候，便把此时的梯度设置成c或-c。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN与RNN能否联合起来用呢？有的，这个称之为RCNN:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/cnnrnn.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./image/netrocompare.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 样本准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
